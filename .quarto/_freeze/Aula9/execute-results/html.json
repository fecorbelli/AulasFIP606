{
  "hash": "16883565a710b8e4de88a699eea03682",
  "result": {
    "markdown": "---\ntitle: \"aula 9\"\nformat: html\neditor: visual\n---\n\n\n## Modelo misto\n\nUm experimento pode ser realizado com diferentes arranjos, ou seja, a forma como dois ou mais fatores estudados ao mesmo tempo são esquematizados. Os arranjos mais utilizados são o fatorial e parcelas subdivididas, podendo ser também combinados.\n\n### Importação dos dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(gsheet)\nmilho <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759\")\n```\n:::\n\n\n### Visualização\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho %>% \n  ggplot(aes(hybrid, index)) +\n  geom_col()\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmilho %>% \n  ggplot(aes(hybrid, yield)) +\n  geom_col()\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n\n```{.r .cell-code}\nmilho %>% \n  ggplot(aes(method, index)) +\n  geom_jitter(width = 0.01, alpha = 0.2)+\n  facet_wrap(~ hybrid) +\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5, color= \"blue\")\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-2-3.png){width=672}\n:::\n\n```{.r .cell-code}\nmilho %>% \n  ggplot(aes(method, yield)) +\n  geom_jitter(width = 0.01, alpha = 0.2)+\n  facet_wrap(~ hybrid) +\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5, color= \"blue\")\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-2-4.png){width=672}\n:::\n:::\n\n\n## Anova parcela subdividida - Index\n\nPara realização dessa análise, devemos considerar o bloco como um fator. Além disso, devemos observar a interação dos fatores híbrido e método, bem como com o bloco.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(lme4)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nCarregando pacotes exigidos: Matrix\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'Matrix'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n```\n:::\n\n```{.r .cell-code}\nlibrary(Matrix)\n\nmilho <- milho %>%  \n  mutate(block = as.factor(block))\n\nmix2 <- lmer(index ~ hybrid*method + block +\n               (1|block/hybrid), data = milho)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nunable to evaluate scaled gradient\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge: degenerate Hessian with 1 negative eigenvalues\n```\n:::\n\n```{.r .cell-code}\nlibrary(car)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nCarregando pacotes exigidos: carData\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'car'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:dplyr':\n\n    recode\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    some\n```\n:::\n\n```{.r .cell-code}\nAnova(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(>Chisq)   \nhybrid        15.5971  5   0.008094 **\nmethod         4.6963  1   0.030228 * \nblock          0.2157  3   0.975023   \nhybrid:method 15.8060  5   0.007420 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nInterpretação: Pelo menos um híbrido se diferencia dos demais. Assim como existe diferença significativa entre os métodos, existe diferença na interação híbrido com método\n\n### Checando as premissas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DHARMa)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n```\n:::\n\n```{.r .cell-code}\nplot(simulateResiduals(mix2))\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_normality(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: residuals appear as normally distributed (p = 0.635).\n```\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n```\n:::\n:::\n\n\n### Transformação para raiz quadrada e ANOVA\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmix22 <- lmer(sqrt(index) ~ hybrid*method + block +\n               (1|block/hybrid), data = milho)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nunable to evaluate scaled gradient\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge: degenerate Hessian with 1 negative eigenvalues\n```\n:::\n\n```{.r .cell-code}\nlibrary(car)\nAnova(mix22)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(index)\n                Chisq Df Pr(>Chisq)   \nhybrid        15.3159  5   0.009095 **\nmethod         3.8886  1   0.048615 * \nblock          0.0718  3   0.994997   \nhybrid:method 13.3812  5   0.020057 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n### Checando as premissas após transformação\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DHARMa)\nplot(simulateResiduals(mix22))\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_normality(mix22)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: residuals appear as normally distributed (p = 0.440).\n```\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix22)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: Error variance appears to be homoscedastic (p = 0.971).\n```\n:::\n:::\n\n\n### Verificação dos grupos distintos estatisticamente\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(emmeans)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n```\n:::\n\n```{.r .cell-code}\nmedias_milho <- emmeans(mix22, ~ hybrid | method,\n                        type = \"response\")\nmedias_milho2 <- emmeans(mix22, ~ method | hybrid,\n                         type = \"response\")\n# quando transforma os dados e necessario adicionar type = response\n\nlibrary (multcomp)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nCarregando pacotes exigidos: mvtnorm\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nCarregando pacotes exigidos: survival\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nCarregando pacotes exigidos: TH.data\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nCarregando pacotes exigidos: MASS\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'MASS'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:dplyr':\n\n    select\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'TH.data'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:MASS':\n\n    geyser\n```\n:::\n\n```{.r .cell-code}\ncld (medias_milho,Letters = LETTERS)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.4 10.7 6084     4.10     46.0  A    \n 30K64        20.3 10.9 6084     4.51     47.4  A    \n 30F53 YH     24.5 12.0 6084     6.61     53.7  AB   \n 30F53 HX     25.0 12.1 6084     6.84     54.4  AB   \n 30S31YH      31.7 13.7 6084    10.57     64.2  AB   \n 30S31H       37.1 14.8 6084    13.79     71.8   B   \n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.1 10.6 6084     3.96     45.6  A    \n 30K64        21.3 11.2 6084     5.00     48.9  A    \n 30F53 HX     24.4 12.0 6084     6.56     53.6  A    \n 30F53 YH     26.0 12.4 6084     7.42     56.0  A    \n 30S31H       26.3 12.5 6084     7.57     56.4  A    \n 30S31YH      26.4 12.5 6084     7.62     56.5  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n:::\n\n```{.r .cell-code}\ncld (medias_milho2, Letters = LETTERS)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 12.0 6084     6.56     53.6  A    \n pin        25.0 12.1 6084     6.84     54.4  A    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 12.0 6084     6.61     53.7  A    \n silk       26.0 12.4 6084     7.42     56.0  A    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.9 6084     4.51     47.4  A    \n silk       21.3 11.2 6084     5.00     48.9  A    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.5 6084     7.57     56.4  A    \n pin        37.1 14.8 6084    13.79     71.8   B   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.5 6084     7.62     56.5  A    \n pin        31.7 13.7 6084    10.57     64.2  A    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.6 6084     3.96     45.6  A    \n pin        19.4 10.7 6084     4.10     46.0  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n:::\n:::\n\n\n## Anova parcela subdividida - Yield\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmix3 <- lmer(yield ~ hybrid*method + block +\n               (1|block/hybrid), data = milho)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nunable to evaluate scaled gradient\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nHessian is numerically singular: parameters are not uniquely determined\n```\n:::\n\n```{.r .cell-code}\nlibrary(car)\nAnova(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yield\n                Chisq Df Pr(>Chisq)    \nhybrid        25.5991  5  0.0001067 ***\nmethod         0.1052  1  0.7456934    \nblock          2.3564  3  0.5018078    \nhybrid:method 25.9302  5  9.206e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n### Checando as premissas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DHARMa)\nplot(simulateResiduals(mix3))\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_normality(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: residuals appear as normally distributed (p = 0.211).\n```\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n```\n:::\n:::\n\n\n### Transformação para raiz quadrada\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmix33 <- lmer(sqrt(yield) ~ hybrid*method + block +\n               (1|block/hybrid), data = milho)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: large eigenvalue ratio\n - Rescale variables?\n```\n:::\n\n```{.r .cell-code}\nlibrary(car)\nAnova(mix33)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(yield)\n                Chisq Df Pr(>Chisq)    \nhybrid        25.5591  5  0.0001086 ***\nmethod         0.0520  1  0.8196750    \nblock          2.3606  3  0.5010021    \nhybrid:method 24.4985  5  0.0001741 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n### Checando as premissas após transformação\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DHARMa)\nplot(simulateResiduals(mix33))\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_normality(mix33)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: residuals appear as normally distributed (p = 0.214).\n```\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix33)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: Error variance appears to be homoscedastic (p = 0.686).\n```\n:::\n:::\n\n\n### Verificação dos grupos distintos estatisticamente\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(emmeans)\nmedias_milho3 <- emmeans(mix33, ~ hybrid | method,\n                        type = \"response\")\nmedias_milho4 <- emmeans(mix33, ~ method | hybrid,\n                         type = \"response\")\n\nlibrary (multcomp)\ncld (medias_milho3,Letters = LETTERS)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nmethod = pin:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      7829 732 26.1     6398     9405  A    \n 30S31H       8081 743 26.1     6626     9681  AB   \n 30F53 YH     9314 798 26.1     7746    11027  ABC  \n 30F53 HX    11130 872 26.1     9410    12995   BC  \n 30K64       11666 893 26.1     9903    13574    C  \n BG7049H     11914 903 26.1    10131    13841    C  \n\nmethod = silk:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      8257 751 26.1     6785     9873  A    \n 30F53 YH     9079 788 26.1     7532    10770  A    \n 30S31H       9135 790 26.1     7583    10832  A    \n 30F53 HX     9932 824 26.1     8311    11698  AB   \n 30K64       10331 840 26.1     8676    12131  AB   \n BG7049H     12822 936 26.1    10970    14818   B   \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n:::\n\n```{.r .cell-code}\ncld (medias_milho4, Letters = LETTERS)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nhybrid = 30F53 HX:\n method response  SE   df lower.CL upper.CL .group\n silk       9932 824 26.1     8311    11698  A    \n pin       11130 872 26.1     9410    12995   B   \n\nhybrid = 30F53 YH:\n method response  SE   df lower.CL upper.CL .group\n silk       9079 788 26.1     7532    10770  A    \n pin        9314 798 26.1     7746    11027  A    \n\nhybrid = 30K64:\n method response  SE   df lower.CL upper.CL .group\n silk      10331 840 26.1     8676    12131  A    \n pin       11666 893 26.1     9903    13574   B   \n\nhybrid = 30S31H:\n method response  SE   df lower.CL upper.CL .group\n pin        8081 743 26.1     6626     9681  A    \n silk       9135 790 26.1     7583    10832   B   \n\nhybrid = 30S31YH:\n method response  SE   df lower.CL upper.CL .group\n pin        7829 732 26.1     6398     9405  A    \n silk       8257 751 26.1     6785     9873  A    \n\nhybrid = BG7049H:\n method response  SE   df lower.CL upper.CL .group\n pin       11914 903 26.1    10131    13841  A    \n silk      12822 936 26.1    10970    14818  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n:::\n:::\n\n\n# Regressão linear\n\nA análise de regressão permite estudar a relação entre uma variável dependente e uma ou mais variáveis independentes. Ela busca estimar uma equação que descreve a relação entre as variáveis.\n\n### Importação dos dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gsheet)\nestande <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n```\n:::\n\n\n### Visualização\n\nPara visualização da reta referente a regressão linear utilizamos o argumento method = “lm” dentro da função `geom_smooth()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestande %>% \n  ggplot(aes(trat,nplants)) +\n  geom_jitter(width = 0.01, alpha = 0.2) +\n  facet_wrap(~ exp) +\n   stat_summary(fun.data = \"mean_cl_boot\", size = 0.5, color= \"blue\") +\n  geom_smooth(method = \"lm\", se = F)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#se = F -> tira a barra de intervalo de confiança\n\nestande %>%  \n  ggplot(aes(trat, nplants, color = factor(exp)))+\n  geom_jitter(width = 0.1, color = \"gray\")+\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"blue\")+\n  geom_smooth(method = \"lm\", se = F)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-14-2.png){width=672}\n:::\n:::\n\n\n### Modelo de melhor ajuste - Experimento 1\n\nPara analisar cada experimento isoladamente, primeiro filtramos o conjunto de dados com a função `filter()`. Depois ajustamos os dados ao modelo linear por meio da função `lm()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp1 <- estande %>% \n  filter(exp == 1)\n\nexp1 %>% \n  ggplot (aes(trat, nplants)) +\n  geom_point() +\n  ylim(0,100) +\n  geom_smooth(se = F) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# modelo linear\n\nlm1 <- lm(nplants ~ trat,\n          data = exp1)\n\nsummary(lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,\tAdjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n```\n:::\n:::\n\n\nInterpretação: Se modelo linear é o que explica melhor, interceptaria em 52 Taxa de redução - 1 planta a cada 4% (-0.242) Ho - coeficiente angular igual a zero (modelo linear) pvalor = 0,21 - não rejeita Ho (taxa de redução não é diferente de zero)\n\n### Modelo de melhor ajuste - Experimento 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp2 <- estande %>% \n  filter(exp == 2)\n\nexp2 %>% \n  ggplot (aes(trat, nplants)) +\n  geom_point() +\n  ylim(0,100) +\n  geom_smooth(se = F) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# modelo linear\n\nlm2 <- lm(nplants ~ trat,\n          data = exp2)\n\nsummary(lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,\tAdjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n```\n:::\n:::\n\n\nInterpretação: -0,70 plantas a cada unidade de x(inóculo) Pvalor significativo, rejeita Ho\n\n### Modelo de melhor ajuste - Experimento 3\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp3 <- estande %>% \n  filter(exp == 3)\n\nexp3 %>% \n  ggplot (aes(trat, nplants)) +\n  geom_point() +\n  ylim(0,100) +\n  geom_smooth(se = F) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 3 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# modelo linear\n\nlm3 <- lm(nplants ~ trat,\n          data = exp3)\n\nsummary(lm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,\tAdjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n```\n:::\n\n```{.r .cell-code}\nhist(residuals(lm3))\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-17-2.png){width=672}\n:::\n:::\n\n\nInterpretação: Coeficiente de determinação (adjusted R-squared): 59% da variabilidade do Y (número de plantas) é explicado pelo X (inóculo)\n\n### Transformações para tornar os dados mais linearizados\n\nPara tornar os dados mais linearizados e o ajuste ser melhor, podemos transformar o conjunto de dados. Para verificar qual transformação se enquadra melhor, observamos o valor de AIC. Quanto menor o AIC melhor o modelo/melhor ajuste.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp2 |> \n  ggplot(aes(log(trat), nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(se = F)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 4 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n```\n:::\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n```{.r .cell-code}\nglm1 <- glm(nplants ~ trat,\n            family = poisson,\n            data = exp1)\n\nsummary(glm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = nplants ~ trat, family = poisson, data = exp1)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  3.963738   0.039359 100.708  < 2e-16 ***\ntrat        -0.005199   0.001862  -2.793  0.00523 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 111.37  on 23  degrees of freedom\nResidual deviance: 103.31  on 22  degrees of freedom\nAIC: 243.58\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\nAIC(glm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 243.5839\n```\n:::\n\n```{.r .cell-code}\nglm1b <- glm(nplants ~ trat,\n            family = poisson(link = \"log\"),\n            data = exp1)\n\nsummary(glm1b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp1)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  3.963738   0.039359 100.708  < 2e-16 ***\ntrat        -0.005199   0.001862  -2.793  0.00523 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 111.37  on 23  degrees of freedom\nResidual deviance: 103.31  on 22  degrees of freedom\nAIC: 243.58\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\nAIC(glm1b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 243.5839\n```\n:::\n\n```{.r .cell-code}\nglm2 <- glm(nplants ~ trat,\n            family = poisson,\n            data = exp2)\n\nsummary(glm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = nplants ~ trat, family = poisson, data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.134189   0.037583 110.003  < 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\nAIC(glm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 210.2353\n```\n:::\n\n```{.r .cell-code}\nglm2b <- glm(nplants ~ trat,\n            family = poisson(link = \"log\"),\n            data = exp2)\n\nsummary(glm2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.134189   0.037583 110.003  < 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\nAIC(glm2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 210.2353\n```\n:::\n\n```{.r .cell-code}\nglm3 <- glm(nplants ~ trat,\n            family = poisson,\n            data = exp3)\n\n\nsummary(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = nplants ~ trat, family = poisson, data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.571590   0.029539 154.762  < 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\nAIC(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 183.9324\n```\n:::\n\n```{.r .cell-code}\nglm3b <- glm(nplants ~ trat,\n            family = poisson(link = \"log\"),\n            data = exp3)\n\nsummary(glm3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.571590   0.029539 154.762  < 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\nAIC(glm3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 183.9324\n```\n:::\n:::\n\n\n## Análise conjunta\n\nQuando há mais de um experimento também podemos realizar uma análise mista, em que é considerada uma média de todos os experimentos.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nglm4 <- glmer(nplants ~ trat + (trat|exp),\n            family = poisson,\n            data = estande)\n\nsummary(glm4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.223397   0.147793  28.577  < 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n```\n:::\n\n```{.r .cell-code}\nAIC(glm4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 660.7282\n```\n:::\n\n```{.r .cell-code}\nglm4b <- glmer(nplants ~ trat + (trat|exp),\n            family = poisson(link = \"log\"),\n            data = estande)\n\nsummary(glm4b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.223397   0.147793  28.577  < 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n```\n:::\n\n```{.r .cell-code}\nAIC(glm4b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 660.7282\n```\n:::\n:::\n\n\n## Relação entre variáveis respostas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nBioconductor version '3.18' is out-of-date; the current release version '3.19'\n  is available with R version '4.4'; see https://bioconductor.org/install\n```\n:::\n\n```{.r .cell-code}\nBiocManager::install(\"Icens\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nBioconductor version 3.18 (BiocManager 1.30.23), R 4.3.3 (2024-02-29 ucrt)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package(s) not installed when version(s) same as or greater than current; use\n  `force = TRUE` to re-install: 'Icens'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nInstallation paths not writeable, unable to update packages\n  path: C:/Program Files/R/R-4.3.3/library\n  packages:\n    boot, codetools, foreign, KernSmooth, lattice, nlme, survival\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nOld packages: 'cli', 'crayon', 'digest', 'emmeans', 'lme4', 'minqa', 'mvtnorm',\n  'nloptr', 'parameters', 'pbkrtest', 'pkgload', 'ps', 'rlang', 'SparseM',\n  'xfun'\n```\n:::\n\n```{.r .cell-code}\nremotes::install_github(\"emdelponte/r4pde\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nDownloading GitHub repo emdelponte/r4pde@HEAD\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nrlang (1.1.3 -> 1.1.4) [CRAN]\ncli   (3.6.2 -> 3.6.3) [CRAN]\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nSkipping 1 packages not available: Icens\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nInstalling 2 packages: rlang, cli\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nInstalling packages into 'C:/Users/Windows/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\npackage 'rlang' successfully unpacked and MD5 sums checked\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: cannot remove prior installation of package 'rlang'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in file.copy(savedcopy, lib, recursive = TRUE): problem copying\nC:\\Users\\Windows\\AppData\\Local\\R\\win-library\\4.3\\00LOCK\\rlang\\libs\\x64\\rlang.dll\nto C:\\Users\\Windows\\AppData\\Local\\R\\win-library\\4.3\\rlang\\libs\\x64\\rlang.dll:\nPermission denied\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: restored 'rlang'\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\npackage 'cli' successfully unpacked and MD5 sums checked\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: cannot remove prior installation of package 'cli'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in file.copy(savedcopy, lib, recursive = TRUE): problem copying\nC:\\Users\\Windows\\AppData\\Local\\R\\win-library\\4.3\\00LOCK\\cli\\libs\\x64\\cli.dll to\nC:\\Users\\Windows\\AppData\\Local\\R\\win-library\\4.3\\cli\\libs\\x64\\cli.dll:\nPermission denied\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: restored 'cli'\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nThe downloaded binary packages are in\n\tC:\\Users\\Windows\\AppData\\Local\\Temp\\RtmpEvGUjf\\downloaded_packages\n── R CMD build ─────────────────────────────────────────────────────────────────\n* checking for file 'C:\\Users\\Windows\\AppData\\Local\\Temp\\RtmpEvGUjf\\remotes2af465736917\\emdelponte-r4pde-42e6615/DESCRIPTION' ... OK\n* preparing 'r4pde':\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\n* building 'r4pde_0.0.0.9000.tar.gz'\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nInstalling package into 'C:/Users/Windows/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n```\n:::\n\n```{.r .cell-code}\nlibrary(r4pde)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: replacing previous import 'car::recode' by 'dplyr::recode' when\nloading 'r4pde'\n```\n:::\n\n```{.r .cell-code}\nwm <- WhiteMoldSoybean\n\nwm %>% \n  ggplot(aes(inc,yld, color = factor(study))) + \n  geom_point() +\n  theme_minimal() +\n  geom_smooth(method = \"lm\", se = F)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# modelo global\nmofo1 <- lm(yld ~inc,\n            data = wm)\n\nsummary(mofo1) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3299.619     56.451  58.451  < 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,\tAdjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n```\n:::\n\n```{.r .cell-code}\n#Intercept é a produtividade com a incidência igual a 0\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\nlibrary(dplyr)\n\nmofo2 <- wm %>% \n  group_by(study) %>% \n  do(tidy(lm(.$yld ~ .$inc), conf.int = TRUE))\n\nmofo2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   <dbl> <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n```\n:::\n\n```{.r .cell-code}\np3 <- mofo2 %>% \n  filter(term == \"(Intercept)\") %>% \n  ggplot(aes(x = estimate)) +\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\") +\n  theme_r4pde() +\n  labs(x = \"Intercept\", y = \"Frequency\")\n\nlibrary(cowplot)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'cowplot'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:lubridate':\n\n    stamp\n```\n:::\n\n```{.r .cell-code}\np4 <- mofo2 %>% \n  filter(term == \".$inc\") %>% \n  ggplot(aes(x = estimate)) +\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\") +\n  theme_r4pde() +\n  labs (x = \"Slope\", y = \"Frequency\")\n\ndf <- mofo2 %>%  filter(term == \".$inc\") \nmean(df$estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -19.52932\n```\n:::\n\n```{.r .cell-code}\nlibrary(patchwork)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'patchwork'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:cowplot':\n\n    align_plots\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:MASS':\n\n    area\n```\n:::\n\n```{.r .cell-code}\np3 + p4\n```\n\n::: {.cell-output-display}\n![](Aula9_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nmofo3 <- lmer(yld ~ inc + (inc| study), data = wm,\n              REML = F)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n```\n:::\n\n```{.r .cell-code}\nsummary(mofo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: yld ~ inc + (inc | study)\n   Data: wm\n\n     AIC      BIC   logLik deviance df.resid \n  5319.4   5343.1  -2653.7   5307.4      376 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7078 -0.5991 -0.0295  0.5077  3.2364 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n study    (Intercept) 557573.08 746.708       \n          inc             36.85   6.071  -0.29\n Residual              37228.73 192.947       \nNumber of obs: 382, groups:  study, 35\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 3455.432    128.063   26.98\ninc          -17.236      1.451  -11.88\n\nCorrelation of Fixed Effects:\n    (Intr)\ninc -0.300\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n```\n:::\n\n```{.r .cell-code}\nAnova (mofo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yld\n     Chisq Df Pr(>Chisq)    \ninc 141.09  1  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nconfint(mofo3, method = \"Wald\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 2.5 %     97.5 %\n.sig01              NA         NA\n.sig02              NA         NA\n.sig03              NA         NA\n.sigma              NA         NA\n(Intercept) 3204.43403 3706.43096\ninc          -20.08046  -14.39219\n```\n:::\n:::\n\n\nInterpretação: Esta estimativa é mais confiável Inc do efeito ficou sendo -17, os outros métodos subestimam A medida que a incidência aumenta, a produtividade diminui em 17kg\n",
    "supporting": [
      "Aula9_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}