[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AulasFIP606",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Aula8.html",
    "href": "Aula8.html",
    "title": "Aula 8",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gsheet)\n\nsoja &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\nPara considerar o bloco como um fator devemos utilizar a função mutate().\n\nsoja &lt;- soja %&gt;% \n  mutate(TRAT = as.factor(TRAT),\n         BLOCO = as.factor(BLOCO))\n\n\n\n\n\nlibrary(Hmisc)\n\n\nAttaching package: 'Hmisc'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    src, summarize\n\n\nThe following objects are masked from 'package:base':\n\n    format.pval, units\n\ndfc &lt;- soja %&gt;%\n  ggplot(aes(TRAT, DFC)) +\n  geom_jitter(width = 0.05, color = \"gray70\") +\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"black\")\n\nfer &lt;- soja %&gt;% \n  ggplot(aes(TRAT, FER))+\n  geom_jitter(width = 0.05, color = \"gray70\") +\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"black\")\n\nprod &lt;- soja %&gt;% \n  ggplot(aes(TRAT, PROD))+\n  geom_jitter(width = 0.05, color = \"gray70\") +\n  stat_summary(fun.data = \"mean_cl_boot\", color = \"black\")\n\nlibrary(patchwork)\n# juntar os gráficos\n(dfc | fer | prod)\n\n\n\n\n\n\n\nNo execução da ANOVA devemos considerar o bloco como elemento da análise “+ BLOCO”.\n\naov_dfc &lt;- lm(DFC ~ TRAT + BLOCO,\n              data = soja)\n\nanova(aov_dfc)\n\nAnalysis of Variance Table\n\nResponse: DFC\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 149.299 21.3284 51.5490 8.218e-12 ***\nBLOCO      3   0.461  0.1537  0.3716    0.7743    \nResiduals 21   8.689  0.4138                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# o bloco não tem efeito, mas deve ser levado em considração\n\n\n\n\nlibrary(performance)\n\ncheck_normality(aov_dfc)\n\nOK: residuals appear as normally distributed (p = 0.978).\n\ncheck_heteroscedasticity(aov_dfc)\n\nOK: Error variance appears to be homoscedastic (p = 0.532).\n\nlibrary(emmeans)\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\nmedias_dfc &lt;- emmeans(aov_dfc, ~ TRAT) \n\nmedias_dfc\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     10.88 0.322 21    10.21    11.54\n 2      6.42 0.322 21     5.76     7.09\n 3      6.05 0.322 21     5.38     6.72\n 4      4.75 0.322 21     4.08     5.42\n 5      4.20 0.322 21     3.53     4.87\n 6      4.00 0.322 21     3.33     4.67\n 7      4.08 0.322 21     3.41     4.74\n 8      4.58 0.322 21     3.91     5.24\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm (medias_dfc)\n\n        1       2       3       4       5       6       7       8\n1 [10.87]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   4.450 [ 6.42]  0.9896  0.0249  0.0017  0.0006  0.0009  0.0107\n3   4.825   0.375 [ 6.05]  0.1329  0.0107  0.0040  0.0058  0.0628\n4   6.125   1.675   1.300 [ 4.75]  0.9202  0.7173  0.8072  0.9999\n5   6.675   2.225   1.850   0.550 [ 4.20]  0.9998  1.0000  0.9896\n6   6.875   2.425   2.050   0.750   0.200 [ 4.00]  1.0000  0.9020\n7   6.800   2.350   1.975   0.675   0.125  -0.075 [ 4.07]  0.9499\n8   6.300   1.850   1.475   0.175  -0.375  -0.575  -0.500 [ 4.57]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:patchwork':\n\n    area\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\ncld (medias_dfc,Letters = LETTERS)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      4.00 0.322 21     3.33     4.67  A    \n 7      4.08 0.322 21     3.41     4.74  A    \n 5      4.20 0.322 21     3.53     4.87  A    \n 8      4.58 0.322 21     3.91     5.24  AB   \n 4      4.75 0.322 21     4.08     5.42  AB   \n 3      6.05 0.322 21     5.38     6.72   BC  \n 2      6.42 0.322 21     5.76     7.09    C  \n 1     10.88 0.322 21    10.21    11.54     D \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\n\naov_fer &lt;- lm(FER ~ TRAT + BLOCO,\n              data = soja)\n\nanova(aov_fer)\n\nAnalysis of Variance Table\n\nResponse: FER\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 978.87 139.838 55.1717 4.218e-12 ***\nBLOCO      3   3.84   1.279  0.5045    0.6834    \nResiduals 21  53.23   2.535                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nlibrary(performance)\ncheck_normality(aov_fer)\n\nWarning: Non-normality of residuals detected (p = 0.008).\n\ncheck_heteroscedasticity(aov_fer)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\nlibrary(DHARMa)\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(aov_fer))\n\nqu = 0.25, log(sigma) = -3.154359 : outer Newton did not converge fully.\n\n\nqu = 0.25, log(sigma) = -3.253793 : outer Newton did not converge fully.\n\n\nqu = 0.25, log(sigma) = -3.254017 : outer Newton did not converge fully.\n\n\nqu = 0.25, log(sigma) = -3.253671 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -2.678463 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -2.88072 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.005722 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.082978 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.130724 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.160233 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.387491 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.822003 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.920457 : outer Newton did not converge fully.\n\n\nqu = 0.75, log(sigma) = -3.91733 : outer Newton did not converge fully.\n\n\n\n\nlibrary(emmeans)\nmedias_fer &lt;- emmeans(aov_fer, ~ TRAT) \n\nmedias_fer\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     20.25 0.796 21    18.59    21.91\n 2      5.88 0.796 21     4.22     7.53\n 3      4.00 0.796 21     2.34     5.66\n 4      3.12 0.796 21     1.47     4.78\n 5      3.25 0.796 21     1.59     4.91\n 6      3.00 0.796 21     1.34     4.66\n 7      3.38 0.796 21     1.72     5.03\n 8      3.50 0.796 21     1.84     5.16\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm (medias_fer)\n\n        1       2       3       4       5       6       7       8\n1 [20.25]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2  14.375 [ 5.87]  0.7076  0.2722  0.3229  0.2273  0.3792  0.4404\n3  16.250   1.875 [ 4.00]  0.9926  0.9971  0.9840  0.9991  0.9998\n4  17.125   2.750   0.875 [ 3.12]  1.0000  1.0000  1.0000  1.0000\n5  17.000   2.625   0.750  -0.125 [ 3.25]  1.0000  1.0000  1.0000\n6  17.250   2.875   1.000   0.125   0.250 [ 3.00]  1.0000  0.9998\n7  16.875   2.500   0.625  -0.250  -0.125  -0.375 [ 3.37]  1.0000\n8  16.750   2.375   0.500  -0.375  -0.250  -0.500  -0.125 [ 3.50]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\ncld (medias_fer,Letters = LETTERS)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      3.00 0.796 21     1.34     4.66  A    \n 4      3.12 0.796 21     1.47     4.78  A    \n 5      3.25 0.796 21     1.59     4.91  A    \n 7      3.38 0.796 21     1.72     5.03  A    \n 8      3.50 0.796 21     1.84     5.16  A    \n 3      4.00 0.796 21     2.34     5.66  A    \n 2      5.88 0.796 21     4.22     7.53  A    \n 1     20.25 0.796 21    18.59    21.91   B   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\nlibrary(MASS)\nb &lt;- boxcox(lm(soja$FER ~ 1))\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] -1.555556\n\nsoja$FER2 &lt;- (soja$FER ^ lambda - 1 / lambda)\n\naov_fer2 &lt;- lm(FER2 ~ TRAT + BLOCO,\n              data = soja)\n\nanova(aov_fer2)\n\nAnalysis of Variance Table\n\nResponse: FER2\n          Df   Sum Sq   Mean Sq F value    Pr(&gt;F)    \nTRAT       7 0.100762 0.0143946 12.9020 2.436e-06 ***\nBLOCO      3 0.014264 0.0047546  4.2616   0.01687 *  \nResiduals 21 0.023429 0.0011157                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nlibrary(performance)\ncheck_normality(aov_fer2)\n\nOK: residuals appear as normally distributed (p = 0.787).\n\ncheck_heteroscedasticity(aov_fer2)\n\nOK: Error variance appears to be homoscedastic (p = 0.872).\n\nlibrary(DHARMa)\nplot(simulateResiduals(aov_fer2))\n\nWe had to increase `err` for some of the quantiles. See fit$calibr$err\nWe had to increase `err` for some of the quantiles. See fit$calibr$err\n\n\n\n\nlibrary(emmeans)\nmedias_fer2 &lt;- emmeans(aov_fer2, ~ TRAT) \n\nmedias_fer2\n\n TRAT emmean     SE df lower.CL upper.CL\n 1     0.653 0.0167 21    0.618    0.687\n 2     0.716 0.0167 21    0.681    0.750\n 3     0.783 0.0167 21    0.748    0.818\n 4     0.822 0.0167 21    0.788    0.857\n 5     0.805 0.0167 21    0.770    0.839\n 6     0.829 0.0167 21    0.794    0.864\n 7     0.795 0.0167 21    0.760    0.830\n 8     0.788 0.0167 21    0.754    0.823\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\nlibrary(multcomp)\ncld (medias_fer2,Letters = LETTERS)\n\n TRAT emmean     SE df lower.CL upper.CL .group\n 1     0.653 0.0167 21    0.618    0.687  A    \n 2     0.716 0.0167 21    0.681    0.750  AB   \n 3     0.783 0.0167 21    0.748    0.818   BC  \n 8     0.788 0.0167 21    0.754    0.823   BC  \n 7     0.795 0.0167 21    0.760    0.830    C  \n 5     0.805 0.0167 21    0.770    0.839    C  \n 4     0.822 0.0167 21    0.788    0.857    C  \n 6     0.829 0.0167 21    0.794    0.864    C  \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\n\naov_prod &lt;- lm(PROD ~ TRAT + BLOCO,\n              data = soja)\n\nanova(aov_prod)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nBLOCO      3  105665   35222  0.2171 0.88340  \nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nlibrary(performance)\ncheck_normality(aov_prod)\n\nOK: residuals appear as normally distributed (p = 0.542).\n\ncheck_heteroscedasticity(aov_prod)\n\nOK: Error variance appears to be homoscedastic (p = 0.215).\n\nlibrary(emmeans)\nmedias_prod &lt;- emmeans(aov_prod, ~ TRAT) \n\nmedias_prod\n\n TRAT emmean  SE df lower.CL upper.CL\n 1      4219 201 21     3800     4638\n 2      4935 201 21     4516     5354\n 3      5110 201 21     4691     5529\n 4      5140 201 21     4721     5559\n 5      5122 201 21     4703     5541\n 6      5256 201 21     4837     5675\n 7      5128 201 21     4709     5546\n 8      5078 201 21     4659     5497\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm (medias_prod)\n\n        1       2       3       4       5       6       7      8\n1  [4219]  0.2430  0.0792  0.0640  0.0728  0.0272  0.0700 0.0985\n2  -715.8  [4935]  0.9983  0.9953  0.9974  0.9430  0.9968 0.9995\n3  -890.8  -175.0  [5110]  1.0000  1.0000  0.9994  1.0000 1.0000\n4  -921.0  -205.3   -30.3  [5140]  1.0000  0.9999  1.0000 1.0000\n5  -902.8  -187.0   -12.0    18.3  [5122]  0.9997  1.0000 1.0000\n6 -1037.0  -321.3  -146.3  -116.0  -134.3  [5256]  0.9998 0.9981\n7  -908.3  -192.5   -17.5    12.8    -5.5   128.8  [5127] 1.0000\n8  -859.0  -143.3    31.7    62.0    43.7   178.0    49.2 [5078]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\nmedias_prod_grupo &lt;- cld (medias_prod,Letters = LETTERS)\n\n\n\n\n\ndf_prod &lt;- data.frame(medias_prod_grupo)\n\ndf_prod %&gt;% \nggplot(aes(TRAT, emmean)) +\n  geom_point() +\n  ylim(2000,6500) +\n  geom_errorbar(aes(min = lower.CL,\n                    max = upper.CL),\n                width = 0.1) +\n  annotate(geom = \"text\", x = 1.1, y = 4200,\n           label = \"A\")\n\n\n\nknitr::kable(df_prod %&gt;% dplyr::select(TRAT, emmean, .group))\n\n\n\n\n\nTRAT\nemmean\n.group\n\n\n\n\n1\n1\n4219.25\nA\n\n\n2\n2\n4935.00\nAB\n\n\n8\n8\n5078.25\nAB\n\n\n3\n3\n5110.00\nAB\n\n\n5\n5\n5122.00\nAB\n\n\n7\n7\n5127.50\nAB\n\n\n4\n4\n5140.25\nAB\n\n\n6\n6\n5256.25\nB\n\n\n\n\n\n\n\n\n\n\nlibrary(gsheet)\n\ncurv &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1807247585\")\n\n\n\n\n\ncurv %&gt;% \n  group_by(Irrigation) %&gt;% \n  summarise(sev_mean = mean(severity),sev_med = median(severity), sd_mean = sd(severity))\n\n# A tibble: 2 × 4\n  Irrigation sev_mean sev_med sd_mean\n  &lt;chr&gt;         &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Drip          0.213   0.165   0.152\n2 Furrow        0.22    0.175   0.159\n\ncurv %&gt;% \n  group_by(day, Irrigation) %&gt;% \n  summarise(sev_mean = mean(severity)) %&gt;% \n  ggplot(aes(day,sev_mean)) +\n  theme_bw() +\n  geom_point(whith = 0.05) +\n  geom_line() + \n  facet_wrap(~~Irrigation)\n\n`summarise()` has grouped output by 'day'. You can override using the `.groups`\nargument.\n\n\nWarning in geom_point(whith = 0.05): Ignoring unknown parameters: `whith`\n\n\n\n\n\n\n\n\nA AUDPC é uma medida utilizada para quantificar e comparar o progresso de doenças em plantas ao longo do tempo. A curva do progresso da doença apresenta o tempo no eixo x e a variável de interesse no eixo y. Utilizamos o elemento AUDPC() na camada summarise.\n\nlibrary(epifitter)\ncurv2 &lt;- curv %&gt;% \n  group_by(Irrigation, rep) %&gt;% \n  summarise(aacpd = AUDPC(day, severity))\n\n`summarise()` has grouped output by 'Irrigation'. You can override using the\n`.groups` argument.\n\nm_curv &lt;- lm(aacpd ~ Irrigation + factor(rep),\n          data = curv2)\n\nlibrary (agricolae)\ncv.model(m_curv)\n\n[1] 1.097572"
  },
  {
    "objectID": "Aula8.html#cálculo-da-área-abaixo-da-curva-de-progresso-da-doença-audpc",
    "href": "Aula8.html#cálculo-da-área-abaixo-da-curva-de-progresso-da-doença-audpc",
    "title": "Aula 8",
    "section": "",
    "text": "A AUDPC é uma medida utilizada para quantificar e comparar o progresso de doenças em plantas ao longo do tempo. A curva do progresso da doença apresenta o tempo no eixo x e a variável de interesse no eixo y. Utilizamos o elemento AUDPC() na camada summarise.\n\nlibrary(epifitter)\ncurv2 &lt;- curv %&gt;% \n  group_by(Irrigation, rep) %&gt;% \n  summarise(aacpd = AUDPC(day, severity))\n\n`summarise()` has grouped output by 'Irrigation'. You can override using the\n`.groups` argument.\n\nm_curv &lt;- lm(aacpd ~ Irrigation + factor(rep),\n          data = curv2)\n\nlibrary (agricolae)\ncv.model(m_curv)\n\n[1] 1.097572"
  },
  {
    "objectID": "Aula6.html",
    "href": "Aula6.html",
    "title": "Aula 6",
    "section": "",
    "text": "Primeiro precisamos importar o conjunto de dados utilizando o pacote gsheet.\n\nlibrary(gsheet)\n\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\n\n\n\nUtilizamos um gráfico boxplot para uma visualização inicial dos dados e observação de características do conjunto.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nmg %&gt;% \n  ggplot (aes(trat,comp))+\n  geom_boxplot()\n\n\n\n\n\n\n\nO teste t é utilizado somente quando há 2 grupos no conjunto de dados. Além disso, é necessário que sejam atendidas as premissas de distribuição normal e a variânça dos grupos sejam homogêneas.\nPara realizar o teste t, os dados precisam se apresentar em grupos separados (formato largo). Assim, é preciso utilizar a função pivot_wider() para o conjunto de dados mg. Para execução do teste t utilizamos a função t.test().\n\nmg2 &lt;- mg %&gt;% \n  pivot_wider(names_from = trat,\n              values_from = comp)\n\nteste1 &lt;- t.test(mg2$Mg2, mg2$control)\n\n\n#Para Utilizar o teste t quando as variânças não são homogêneas, deve adicionar var.qual = false \n\n#t.test(mg2$Mg2, mg2$control),\n#var.equal = FALSE\n\nInterpretação: Pelo teste realizado, temos que a média de Mg2 é 10.52 e a média do controle é de 15.678. O valor do pvalor é menor que 0,05, então se rejeita Ho. O intervalo de confiança apresentado se refere a diferença entre as médias.\n\n\n\nA função shapiro.test() testa se a distribuição é normal. Se pvalor é maior que 0,05, então não rejeita Ho e assume que há normalidade.\n\nshapiro.test(mg2$control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$control\nW = 0.93886, p-value = 0.5404\n\nshapiro.test(mg2$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$Mg2\nW = 0.97269, p-value = 0.9146\n\n\nA função var.test() é utilizada para verificar se as variânças são homogêneas. Quando pvalor é maior que 0,05, então não rejeita Ho e assume que as variânças são homogêneas.\n\nvar.test(mg2$control, mg2$Mg2)\n\n\n    F test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\n\nUma outra forma de verificar normalidade é utilizando as funções gráficas qqnorm() e qqline(). Será um indicativo visual de normalidade, em que, se a maioria dos pontos estiverem sobre a linha há indicativo de normalidade.\n\nqqnorm(mg2$control)\nqqline(mg2$control)\n\n\n\n\n\n\n\nPara criar um texto a respeito dos resultados do teste, pode-se utilizar o pacote report com a função report().\n\nlibrary(report)\nreport (teste1)\n\nWarning: Function `format_text()` is deprecated and will be removed in a future\n  release. Please use `text_format()` instead.\n\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$Mg2 and\nmg2$control (mean of x = 10.52, mean of y = 15.68) suggests that the effect is\nnegative, statistically significant, and large (difference = -5.16, 95% CI\n[-6.49, -3.83], t(17.35) = -8.15, p &lt; .001; Cohen's d = -3.65, 95% CI [-5.12,\n-2.14])\n\n\n\n\n\n\nQuando há dois grupos dependentes, deve ser realizado o teste t pareado.\n\n\n\nescala &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n\n\n\n\n\nescala %&gt;% \n  ggplot (aes(assessment, acuracia)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nescala2 &lt;- escala %&gt;% \n  select(assessment, rater, acuracia) %&gt;% \n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\n\n\n\n\nNo caso do teste t pareado, adicionamos paired = TRUE ao script do teste.\n\n# Verificar se há normalidade\nshapiro.test(escala2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n\nshapiro.test(escala2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n\n#Verificar se as varianças são homogêneas\nvar.test(escala2$Unaided, escala2$Aided1)\n\n\n    F test to compare two variances\n\ndata:  escala2$Unaided and escala2$Aided1\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n\n# Realizado com os dados originais\nt.test(escala2$Aided1, escala2$Unaided,\n       paired = TRUE,\n       var.equal = FALSE)\n\n\n    Paired t-test\n\ndata:  escala2$Aided1 and escala2$Unaided\nt = 4.4214, df = 9, p-value = 0.001668\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1147647 0.3552353\nsample estimates:\nmean difference \n          0.235 \n\n\n\n\n\n\nNo teste não paramétrico não é necessário o atendimento das premissas para execução do teste estatístico.\n\n\nWilcox test é o equivalente não paramétrico do teste t. Utilizamos a função wilcox.test().\n\nwilcox.test(escala2$Aided1,\n            escala2$Unaided,\n            paired = TRUE)\n\nWarning in wilcox.test.default(escala2$Aided1, escala2$Unaided, paired = TRUE):\nnão é possível computar o valor de p exato com o de desempate\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  escala2$Aided1 and escala2$Unaided\nV = 55, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\n\n\nQuando há três ou mais grupos de dados, realizamos uma análise de variânça (ANOVA). A ANOVA irá verificar se pelo menos uma das médias difere das demais.\n\n\n\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\n\n\n\n\nmicelial %&gt;%  \n  ggplot (aes(especie, tcm)) +\n  geom_jitter(width = 0.05)\n\n\n\n\n\n\n\nOs dados devem ser ajustados para o modelo de ANOVA por meio da função lm() e o teste em si é realizado por meio da função anova(). A função summary permite a visualização de um resumo estatistico do teste.\n\nm1 &lt;- lm(tcm ~ especie, data = micelial)\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.57167    0.05585  28.140  &lt; 2e-16 ***\nespecieFaus -0.33500    0.07899  -4.241 0.000266 ***\nespecieFcor -0.25000    0.07899  -3.165 0.004047 ** \nespecieFgra -0.66000    0.07899  -8.356 1.05e-08 ***\nespecieFmer -0.14500    0.07899  -1.836 0.078317 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.7585,    Adjusted R-squared:  0.7199 \nF-statistic: 19.63 on 4 and 25 DF,  p-value: 2.028e-07\n\n# coloca -1 após a especie para ter as médias diretamente\n\n\n\n\nNa análise de variânça utilizamos a função shapiro.test() para verificação da normalidade e a função bartlett.test() para verificação da homogeneidade da variânça.\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.9821, p-value = 0.8782\n\nbartlett.test(tcm ~ especie, data = micelial)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\n\nNomenclaturas ANOVA: sum sq = somatório dos quadrados; df = graus de liberdade; mean sq = média dos quadrados -&gt; sum sq / df; F value = valor F -&gt; Mean sq fator / Mean sq residuo\n\n\n\nPara verificar os grupos que são distintos estatisticamente, primeiro calculamos as médias dos grupos por meio da função emmeans() do pacote emmeans. Depois utilizamos a função cld()do pacote multcomp para visualizar os grupamentos distintos.\n\nlibrary(emmeans)\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\nmedias1 &lt;- emmeans(m1, ~ especie)\n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\nlibrary(multcompView)\ncld (medias1)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\nPodemos analisar de forma gráfica as premissas por meio da função plot (simulateResiduals()) do pacote DHARMa ou pela função check_model() do pacote see.\nTambém podemos verificar as premissas diretamente pelas funções check_normality() e check_heteroscedasticity() do pacote performance.\n\nlibrary (DHARMa)\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(m1))\n\n\n\nlibrary(performance)\ncheck_normality(m1)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\ncheck_heteroscedasticity(m1)\n\nOK: Error variance appears to be homoscedastic (p = 0.880).\n\nlibrary(see)\ncheck_model(m1)"
  },
  {
    "objectID": "Aula6.html#dois-grupos-independentes",
    "href": "Aula6.html#dois-grupos-independentes",
    "title": "Aula 6",
    "section": "",
    "text": "Primeiro precisamos importar o conjunto de dados utilizando o pacote gsheet.\n\nlibrary(gsheet)\n\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\n\n\n\nUtilizamos um gráfico boxplot para uma visualização inicial dos dados e observação de características do conjunto.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nmg %&gt;% \n  ggplot (aes(trat,comp))+\n  geom_boxplot()\n\n\n\n\n\n\n\nO teste t é utilizado somente quando há 2 grupos no conjunto de dados. Além disso, é necessário que sejam atendidas as premissas de distribuição normal e a variânça dos grupos sejam homogêneas.\nPara realizar o teste t, os dados precisam se apresentar em grupos separados (formato largo). Assim, é preciso utilizar a função pivot_wider() para o conjunto de dados mg. Para execução do teste t utilizamos a função t.test().\n\nmg2 &lt;- mg %&gt;% \n  pivot_wider(names_from = trat,\n              values_from = comp)\n\nteste1 &lt;- t.test(mg2$Mg2, mg2$control)\n\n\n#Para Utilizar o teste t quando as variânças não são homogêneas, deve adicionar var.qual = false \n\n#t.test(mg2$Mg2, mg2$control),\n#var.equal = FALSE\n\nInterpretação: Pelo teste realizado, temos que a média de Mg2 é 10.52 e a média do controle é de 15.678. O valor do pvalor é menor que 0,05, então se rejeita Ho. O intervalo de confiança apresentado se refere a diferença entre as médias.\n\n\n\nA função shapiro.test() testa se a distribuição é normal. Se pvalor é maior que 0,05, então não rejeita Ho e assume que há normalidade.\n\nshapiro.test(mg2$control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$control\nW = 0.93886, p-value = 0.5404\n\nshapiro.test(mg2$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$Mg2\nW = 0.97269, p-value = 0.9146\n\n\nA função var.test() é utilizada para verificar se as variânças são homogêneas. Quando pvalor é maior que 0,05, então não rejeita Ho e assume que as variânças são homogêneas.\n\nvar.test(mg2$control, mg2$Mg2)\n\n\n    F test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\n\nUma outra forma de verificar normalidade é utilizando as funções gráficas qqnorm() e qqline(). Será um indicativo visual de normalidade, em que, se a maioria dos pontos estiverem sobre a linha há indicativo de normalidade.\n\nqqnorm(mg2$control)\nqqline(mg2$control)\n\n\n\n\n\n\n\nPara criar um texto a respeito dos resultados do teste, pode-se utilizar o pacote report com a função report().\n\nlibrary(report)\nreport (teste1)\n\nWarning: Function `format_text()` is deprecated and will be removed in a future\n  release. Please use `text_format()` instead.\n\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$Mg2 and\nmg2$control (mean of x = 10.52, mean of y = 15.68) suggests that the effect is\nnegative, statistically significant, and large (difference = -5.16, 95% CI\n[-6.49, -3.83], t(17.35) = -8.15, p &lt; .001; Cohen's d = -3.65, 95% CI [-5.12,\n-2.14])"
  },
  {
    "objectID": "Aula6.html#dois-grupos-dependentes",
    "href": "Aula6.html#dois-grupos-dependentes",
    "title": "Aula 6",
    "section": "",
    "text": "Quando há dois grupos dependentes, deve ser realizado o teste t pareado.\n\n\n\nescala &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n\n\n\n\n\nescala %&gt;% \n  ggplot (aes(assessment, acuracia)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nescala2 &lt;- escala %&gt;% \n  select(assessment, rater, acuracia) %&gt;% \n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\n\n\n\n\nNo caso do teste t pareado, adicionamos paired = TRUE ao script do teste.\n\n# Verificar se há normalidade\nshapiro.test(escala2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n\nshapiro.test(escala2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n\n#Verificar se as varianças são homogêneas\nvar.test(escala2$Unaided, escala2$Aided1)\n\n\n    F test to compare two variances\n\ndata:  escala2$Unaided and escala2$Aided1\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n\n# Realizado com os dados originais\nt.test(escala2$Aided1, escala2$Unaided,\n       paired = TRUE,\n       var.equal = FALSE)\n\n\n    Paired t-test\n\ndata:  escala2$Aided1 and escala2$Unaided\nt = 4.4214, df = 9, p-value = 0.001668\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1147647 0.3552353\nsample estimates:\nmean difference \n          0.235"
  },
  {
    "objectID": "Aula6.html#teste-não-paramétrico",
    "href": "Aula6.html#teste-não-paramétrico",
    "title": "Aula 6",
    "section": "",
    "text": "No teste não paramétrico não é necessário o atendimento das premissas para execução do teste estatístico.\n\n\nWilcox test é o equivalente não paramétrico do teste t. Utilizamos a função wilcox.test().\n\nwilcox.test(escala2$Aided1,\n            escala2$Unaided,\n            paired = TRUE)\n\nWarning in wilcox.test.default(escala2$Aided1, escala2$Unaided, paired = TRUE):\nnão é possível computar o valor de p exato com o de desempate\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  escala2$Aided1 and escala2$Unaided\nV = 55, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "Aula6.html#três-ou-mais-grupos-de-dados",
    "href": "Aula6.html#três-ou-mais-grupos-de-dados",
    "title": "Aula 6",
    "section": "",
    "text": "Quando há três ou mais grupos de dados, realizamos uma análise de variânça (ANOVA). A ANOVA irá verificar se pelo menos uma das médias difere das demais.\n\n\n\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\n\n\n\n\nmicelial %&gt;%  \n  ggplot (aes(especie, tcm)) +\n  geom_jitter(width = 0.05)\n\n\n\n\n\n\n\nOs dados devem ser ajustados para o modelo de ANOVA por meio da função lm() e o teste em si é realizado por meio da função anova(). A função summary permite a visualização de um resumo estatistico do teste.\n\nm1 &lt;- lm(tcm ~ especie, data = micelial)\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.57167    0.05585  28.140  &lt; 2e-16 ***\nespecieFaus -0.33500    0.07899  -4.241 0.000266 ***\nespecieFcor -0.25000    0.07899  -3.165 0.004047 ** \nespecieFgra -0.66000    0.07899  -8.356 1.05e-08 ***\nespecieFmer -0.14500    0.07899  -1.836 0.078317 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.7585,    Adjusted R-squared:  0.7199 \nF-statistic: 19.63 on 4 and 25 DF,  p-value: 2.028e-07\n\n# coloca -1 após a especie para ter as médias diretamente\n\n\n\n\nNa análise de variânça utilizamos a função shapiro.test() para verificação da normalidade e a função bartlett.test() para verificação da homogeneidade da variânça.\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.9821, p-value = 0.8782\n\nbartlett.test(tcm ~ especie, data = micelial)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\n\nNomenclaturas ANOVA: sum sq = somatório dos quadrados; df = graus de liberdade; mean sq = média dos quadrados -&gt; sum sq / df; F value = valor F -&gt; Mean sq fator / Mean sq residuo\n\n\n\nPara verificar os grupos que são distintos estatisticamente, primeiro calculamos as médias dos grupos por meio da função emmeans() do pacote emmeans. Depois utilizamos a função cld()do pacote multcomp para visualizar os grupamentos distintos.\n\nlibrary(emmeans)\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\nmedias1 &lt;- emmeans(m1, ~ especie)\n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\nlibrary(multcompView)\ncld (medias1)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\nPodemos analisar de forma gráfica as premissas por meio da função plot (simulateResiduals()) do pacote DHARMa ou pela função check_model() do pacote see.\nTambém podemos verificar as premissas diretamente pelas funções check_normality() e check_heteroscedasticity() do pacote performance.\n\nlibrary (DHARMa)\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(m1))\n\n\n\nlibrary(performance)\ncheck_normality(m1)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\ncheck_heteroscedasticity(m1)\n\nOK: Error variance appears to be homoscedastic (p = 0.880).\n\nlibrary(see)\ncheck_model(m1)"
  },
  {
    "objectID": "Aula4.html",
    "href": "Aula4.html",
    "title": "Aula4",
    "section": "",
    "text": "O comando datapasta permite copiar vetores de outros locais e colar diretamente no programa. As opções de colagem se encontram no menu “Addins”.\n\ndat &lt;- data.frame(\n  stringsAsFactors = FALSE,\n              trat = c(\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\n                       \"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"control\",\n                       \"control\",\"control\",\"control\",\"control\",\"control\",\"control\",\n                       \"control\",\"control\",\"control\"),\n               rep = c(1L,2L,3L,4L,5L,6L,7L,8L,\n                       9L,10L,1L,2L,3L,4L,5L,6L,7L,8L,9L,10L),\n              comp = c(9,125,10,8,132,11,108,95,\n                       108,104,1372,1591,157,142,159,1654,18,144,\n                       1641,16))\n\ndat\n\n      trat rep comp\n1      Mg2   1    9\n2      Mg2   2  125\n3      Mg2   3   10\n4      Mg2   4    8\n5      Mg2   5  132\n6      Mg2   6   11\n7      Mg2   7  108\n8      Mg2   8   95\n9      Mg2   9  108\n10     Mg2  10  104\n11 control   1 1372\n12 control   2 1591\n13 control   3  157\n14 control   4  142\n15 control   5  159\n16 control   6 1654\n17 control   7   18\n18 control   8  144\n19 control   9 1641\n20 control  10   16\n\n\nExemplo utilizando os dados da tabela “dados.diversos” e o comando “paste as tribble”.\n\ndat2 &lt;- tibble::tribble(\n              ~trat, ~rep, ~comp,\n              \"Mg2\",   1L,     9,\n              \"Mg2\",   2L,   125,\n              \"Mg2\",   3L,    10,\n              \"Mg2\",   4L,     8,\n              \"Mg2\",   5L,   132,\n              \"Mg2\",   6L,    11,\n              \"Mg2\",   7L,   108,\n              \"Mg2\",   8L,    95,\n              \"Mg2\",   9L,   108,\n              \"Mg2\",  10L,   104,\n          \"control\",   1L,  1372,\n          \"control\",   2L,  1591,\n          \"control\",   3L,   157,\n          \"control\",   4L,   142,\n          \"control\",   5L,   159,\n          \"control\",   6L,  1654,\n          \"control\",   7L,    18,\n          \"control\",   8L,   144,\n          \"control\",   9L,  1641,\n          \"control\",  10L,    16\n          )\n\ndat2\n\n# A tibble: 20 × 3\n   trat      rep  comp\n   &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;\n 1 Mg2         1     9\n 2 Mg2         2   125\n 3 Mg2         3    10\n 4 Mg2         4     8\n 5 Mg2         5   132\n 6 Mg2         6    11\n 7 Mg2         7   108\n 8 Mg2         8    95\n 9 Mg2         9   108\n10 Mg2        10   104\n11 control     1  1372\n12 control     2  1591\n13 control     3   157\n14 control     4   142\n15 control     5   159\n16 control     6  1654\n17 control     7    18\n18 control     8   144\n19 control     9  1641\n20 control    10    16\n\n\nExemplo utilizando o comando “paste as tribble” a partir de dados disponíveis em uma página na internet.\n\npop &lt;- tibble::tribble(\n  ~`Pos.    País    População   Área.(km²)  Densidade.(habitantes.por.km²)`,\n                                \"0\\t Macau\\t649 335\\t28,6\\t22 402\",\n                                \"1\\t Mônaco\\t37 308\\t2,02\\t18 713\",\n                 \"2\\tSingapura Singapura\\t5 638 700\\t716,1\\t7 874\",\n                          \"3\\t Hong Kong\\t7 184 000\\t1 104\\t6 544\",\n                                  \"4\\t Vaticano\\t825\\t0,49\\t1 891\",\n                                  \"5\\t Malta\\t417 617\\t316\\t1 321\",\n                               \"6\\t Maldivas\\t427 756\\t300\\t1 426\",\n           \"7\\tBangladesh Bangladesh\\t163 220 762\\t144 000\\t1 113\",\n                           \"8\\t Bahrein\\t1 442 659[1]\\t665\\t1 035\",\n                                 \"9\\t Barbados\\t279 254\\t431\\t647\",\n                            \"10\\t Taiwan\\t22 894 384\\t35 980\\t636\",\n                                                          \"︀慴됨捈ݡ退\",\n                                                           \"\\001\"\n  )"
  },
  {
    "objectID": "Aula4.html#visualização-gráfica",
    "href": "Aula4.html#visualização-gráfica",
    "title": "Aula4",
    "section": "Visualização gráfica",
    "text": "Visualização gráfica\n\npepper %&gt;% \n  pivot_longer(2:4,\n               names_to = \"epidemic\",\n               values_to = \"inc\") %&gt;% \nggplot(aes(t,inc, color = epidemic))+\n  geom_point()"
  },
  {
    "objectID": "Aula2.html",
    "href": "Aula2.html",
    "title": "Aula2",
    "section": "",
    "text": "Alguns pacotes apresentam diferentes conjuntos de dados que podem ser utilizados. Para utilizá-los, basta baixar o pacote, ativar o mesmo e criar um objeto com o conjunto de dados do pacote que você quer trabalhar.\n\nlibrary(ec50estimator)\ndf1 &lt;- multi_isolate\n\n\n\n\nPara a importação de dados que estão em um arquivo excel devemos utilizar a função read_excel do pacote readxl. O comando será: read_excel(“nome do arquivo”).\n\nlibrary(readxl)\ndf2 &lt;- read_excel(\"dados-diversos.xlsx\")\ndf21 &lt;- read_excel(\"dados-diversos.xlsx\",sheet = \"armazena\")\n\n\n\n\nPara a importação de dados que estão em um arquivo csv utilizamos a função read_csv do pacote tidyverse. O comando será: read_csv(“nome do arquivo”).\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndf3 &lt;- read_csv(\"dados-diversos.csv\")\n\nRows: 60 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Irrigation\ndbl (3): rep, day, severity\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nPara a importação de dados que estão em uma planilha google utilizamos a função gsheet2tbl do pacote gsheet. O comando será: gsheet2tb1(“endereço na web”).\n\nlibrary(gsheet)\ndf4 &lt;- gsheet2tbl (\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=959387827#gid=959387827\")"
  },
  {
    "objectID": "Aula2.html#pacotes",
    "href": "Aula2.html#pacotes",
    "title": "Aula2",
    "section": "",
    "text": "Alguns pacotes apresentam diferentes conjuntos de dados que podem ser utilizados. Para utilizá-los, basta baixar o pacote, ativar o mesmo e criar um objeto com o conjunto de dados do pacote que você quer trabalhar.\n\nlibrary(ec50estimator)\ndf1 &lt;- multi_isolate"
  },
  {
    "objectID": "Aula2.html#arquivo-excel",
    "href": "Aula2.html#arquivo-excel",
    "title": "Aula2",
    "section": "",
    "text": "Para a importação de dados que estão em um arquivo excel devemos utilizar a função read_excel do pacote readxl. O comando será: read_excel(“nome do arquivo”).\n\nlibrary(readxl)\ndf2 &lt;- read_excel(\"dados-diversos.xlsx\")\ndf21 &lt;- read_excel(\"dados-diversos.xlsx\",sheet = \"armazena\")"
  },
  {
    "objectID": "Aula2.html#arquivo-csv",
    "href": "Aula2.html#arquivo-csv",
    "title": "Aula2",
    "section": "",
    "text": "Para a importação de dados que estão em um arquivo csv utilizamos a função read_csv do pacote tidyverse. O comando será: read_csv(“nome do arquivo”).\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndf3 &lt;- read_csv(\"dados-diversos.csv\")\n\nRows: 60 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Irrigation\ndbl (3): rep, day, severity\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Aula2.html#planilha-google",
    "href": "Aula2.html#planilha-google",
    "title": "Aula2",
    "section": "",
    "text": "Para a importação de dados que estão em uma planilha google utilizamos a função gsheet2tbl do pacote gsheet. O comando será: gsheet2tb1(“endereço na web”).\n\nlibrary(gsheet)\ndf4 &lt;- gsheet2tbl (\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=959387827#gid=959387827\")"
  },
  {
    "objectID": "Aula2.html#gráficos-em-ggplot",
    "href": "Aula2.html#gráficos-em-ggplot",
    "title": "Aula2",
    "section": "Gráficos em ggplot",
    "text": "Gráficos em ggplot\nPodemos utilizar a biblioteca ggplot2 para vizualizar dados. A função necessária nesse caso é a ggplot. A programação de gráficos em ggplot2 é feito na forma de camadas, que são adicionadas à medida que se confecciona o gráfico.\nA função geom_jitter() irá criar um gráfico de pontos, sendo que esses pontos serão plotados de forma dispersa para não haver sobreposição de dados. Já a função geom_boxplot() irá criar um gráfico do tipo boxplot com os dados. Utilizamos “color =” para definir a coloração dos pontos, “shape =” para definir o formato e “size =” para definir o tamanho. A função outlier.colour = NAé utilizada para que os pontos outlier não apareçam no boxplot.\n\nlibrary(ggplot2)\n\ndf4 %&gt;% \n  ggplot(aes(especie,tcm))+\n  geom_jitter(width = 0.05, color = \"black\", shape = 2, size = 3)+\n  geom_boxplot()\n\n\n\nlibrary(ggplot2)\ng2 &lt;- df4 %&gt;% \n  ggplot(aes(especie,tcm))+\n  geom_boxplot(outlier.colour = NA, fill = \"green\")+\n  geom_jitter(width = 0.05, color = \"black\", shape = 2, size = 3)\n\nPara adicionar anotações ao gráfico utilizamos a função labs().\n\ng2 + theme_classic() + labs(x=\"tratamento\", y= \"comprimento (nm)\", title= \"meu primeiro ggplot\", caption=\"fonte: Dados diversos\") + scale_y_continuous(limits = c(0,2))\n\n\n\ng2 + theme_classic() + labs(x=\"tratamento\", y= \"comprimento (nm)\", title= \"meu primeiro ggplot\", caption=\"fonte: Dados diversos\") + ylim(0,1.5)\n\nWarning: Removed 9 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 9 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nPara salvar o gráfico, utilizamos a função ggsave().\n\nggsave(\"plot1.png\", bg= \"white\")\n\nSaving 7 x 5 in image\n\n\nWarning: Removed 9 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 10 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "Aula10.html",
    "href": "Aula10.html",
    "title": "Aula 10",
    "section": "",
    "text": "A análise de correlação permite verificar se as variáveis estão positivamente correlacionadas (quando uma aumenta, a outra também aumenta), negativamente correlacionadas (quando uma aumenta, a outra diminui) ou se não há correlação entre elas.\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gsheet)\n\nimgs &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=373270992\")\n\n\n\n\n\nimgs %&gt;% \n  ggplot(aes(Assess, LeafDoctor)) +\n  geom_point()\n\n\n\nimgs %&gt;% \n  ggplot(aes(Assess, ImageJ)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nPodemos verificar a correlação entre variáveis atraves da função cor.test() ou da função corgraph() do pacote AgroR.\n\nimgs2 &lt;- imgs %&gt;% \n  select(3:5)\n\nlibrary(dplyr)\nlibrary(AgroR)\n\n\nAttaching package: 'AgroR'\n\n\nThe following object is masked from 'package:dplyr':\n\n    desc\n\ncorgraph(imgs2)\n\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n\n\n\n\ncor.test(imgs$Assess, imgs$LeafDoctor)\n\n\n    Pearson's product-moment correlation\n\ndata:  imgs$Assess and imgs$LeafDoctor\nt = 31.119, df = 68, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9466882 0.9792005\nsample estimates:\n      cor \n0.9666367 \n\n# testa se coeficiente é zero (h0)\ncor(imgs$Assess, imgs$LeafDoctor)\n\n[1] 0.9666367\n\n\nInterpretação: correlação forte Quanto maior a correlação, menor p-valor\n\nlibrary(corrplot)\n\ncorrplot 0.92 loaded\n\ncor_imgs2 &lt;- cor(imgs2)\ncorrplot(cor_imgs2, method = 'number', type = \"lower\", diag = FALSE)\n\n\n\n\n\n\n\n\ncampo &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\ncampo2 &lt;- campo %&gt;% \n  select(DFC, FER, PROD)\n\ncorgraph(campo2)\n\n  Var1 Var2        cor            p\n2  FER  DFC  0.9316978 9.864101e-15\n3 PROD  DFC -0.6928161 1.110652e-05\n6 PROD  FER -0.6258321 1.277444e-04\n\n\n\n\ncampo %&gt;% \n  ggplot(aes(DFC, PROD)) +\n  geom_point()"
  },
  {
    "objectID": "Aula10.html#análise-de-correlação-com-outros-conjuntos-de-dados",
    "href": "Aula10.html#análise-de-correlação-com-outros-conjuntos-de-dados",
    "title": "Aula 10",
    "section": "",
    "text": "campo &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\ncampo2 &lt;- campo %&gt;% \n  select(DFC, FER, PROD)\n\ncorgraph(campo2)\n\n  Var1 Var2        cor            p\n2  FER  DFC  0.9316978 9.864101e-15\n3 PROD  DFC -0.6928161 1.110652e-05\n6 PROD  FER -0.6258321 1.277444e-04\n\n\n\n\ncampo %&gt;% \n  ggplot(aes(DFC, PROD)) +\n  geom_point()"
  },
  {
    "objectID": "Aula10.html#análise-de-regressão-com-modelo-linear---primeira-ordem",
    "href": "Aula10.html#análise-de-regressão-com-modelo-linear---primeira-ordem",
    "title": "Aula 10",
    "section": "Análise de regressão com modelo linear - primeira ordem",
    "text": "Análise de regressão com modelo linear - primeira ordem\n\nlm2 &lt;- lm(nplants ~ trat,\n          data = exp2)\n\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473"
  },
  {
    "objectID": "Aula10.html#análise-de-regressão-com-modelo-quadratico---segunda-ordem",
    "href": "Aula10.html#análise-de-regressão-com-modelo-quadratico---segunda-ordem",
    "title": "Aula 10",
    "section": "Análise de regressão com modelo quadratico - segunda ordem",
    "text": "Análise de regressão com modelo quadratico - segunda ordem\n\nexp2$trat2 &lt;- exp2$trat^2\n\nlm3 &lt;- lm(nplants ~ trat + trat2,\n          data = exp2)\n\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat + trat2, data = exp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.439  -6.019   1.789   8.016  19.561 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 66.30156    4.42097  14.997 1.08e-12 ***\ntrat        -1.77720    0.58467  -3.040  0.00623 ** \ntrat2        0.02223    0.01166   1.906  0.07036 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.24 on 21 degrees of freedom\nMultiple R-squared:  0.5432,    Adjusted R-squared:  0.4997 \nF-statistic: 12.49 on 2 and 21 DF,  p-value: 0.0002675\n\nAIC(lm2)\n\n[1] 194.9597\n\nAIC(lm3)\n\n[1] 193.1284\n\n\nInterpretação: Maior o valor de r2 no segundo modelo, então o modelo quadrático explica melhor a relação entre variáveis. Função = 66,3 - 1,77* TRAT + 0,02* TRAT2\n\nlibrary(AgroR)\nwith(exp2, polynomial(trat, nplants, grau = 2))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 66.30156250 4.42096799 14.997069 1.079972e-12\ntrat        -1.77719814 0.58467380 -3.039640 6.230050e-03\nI(trat^2)    0.02222876 0.01165948  1.906496 7.036247e-02\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ         F      p-value\nLinear     1 3196.2031 3196.2031 21.823293 0.0001899378\nQuadratic  1  544.5029  544.5029  3.717801 0.0697619482\nDeviation  3  509.6690  169.8897  1.159986 0.3523240106\nResidual  18 2636.2500  146.4583                       \n\n\n[[1]]\n\n\n\n\ndata(\"phao\")\nwith(phao, polynomial(dose, comp, grau = 2))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n              Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 10.2097143 0.68981140 14.800733 6.427099e-13\ntrat         2.8822857 0.40856781  7.054608 4.456995e-07\nI(trat^2)   -0.3042857 0.04897332 -6.213296 2.971498e-06\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df        SSq         MSQ          F      p-value\nLinear     1  40.140800  40.1408000 14.0529338 1.265122e-03\nQuadratic  1 103.700571 103.7005714 36.3046392 6.852202e-06\nDeviation  2   1.968229   0.9841143  0.3445296 7.126767e-01\nResidual  20  57.128000   2.8564000                        \n\n\n[[1]]\n\n\n\n\n\ncoeficiente de correlação maior que coeficiente de regressão - precisa de relação de causa e efeito\nr2 - o quanto de y é explicado por x r - força de associação entre x e y"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Aula1.html",
    "href": "Aula1.html",
    "title": "Aula1",
    "section": "",
    "text": "O R é uma linguagem de programação estatistica gratuita e de livre acesso.\n\n\nUm pacote é um grupamento de funções, dados e arquivos que podem ser utilizados no R. Há milhares de pacotes que são desenvolvidos e disponibilizados em repositórios para download e que podem nos auxiliar em nosso trabalho.\n\n\nA instalação de pacotes pode ser feita pelo menu ou então com um comando no console. A instalação é feita através do menu em tools &gt; install packages e digitando o nome do pacote para baixar ou usando a função instal.packages(nome do pacote) no console.\nApós realizar a instalação do pacote, ele não estará disponível para uso imediatamente. Para habilitar o pacote para uso, se deve utilizar a função library(nome do pacote).\n\nlibrary(epifitter)\n\n\n\n\n\nUm objeto é um nome que armazena um valor. Para criá-lo utilizamos &lt;- .\n\nx &lt;- 10\ny &lt;- x * 10\n\n\n\nPara criar um objeto que seja um conjunto de dados numéricos compreendidos em um intervalo, basta utilizar a função c(valor : valor).\n\na &lt;- c(1:10)\nb &lt;- c(11:20)\n\n\n\n\n\nUm data-frame é uma estrutura para armazenar dados e é um objeto bidirecional. Ele pode conter uma mistura de diferentes tipos de dados, mas cada coluna deve ter o mesmo número de observações.\n\ndata.frame(pressure)\n\n   temperature pressure\n1            0   0.0002\n2           20   0.0012\n3           40   0.0060\n4           60   0.0300\n5           80   0.0900\n6          100   0.2700\n7          120   0.7500\n8          140   1.8500\n9          160   4.2000\n10         180   8.8000\n11         200  17.3000\n12         220  32.1000\n13         240  57.0000\n14         260  96.0000\n15         280 157.0000\n16         300 247.0000\n17         320 376.0000\n18         340 558.0000\n19         360 806.0000\n\ndf &lt;- data.frame(a,b)\n\ndf\n\n    a  b\n1   1 11\n2   2 12\n3   3 13\n4   4 14\n5   5 15\n6   6 16\n7   7 17\n8   8 18\n9   9 19\n10 10 20"
  },
  {
    "objectID": "Aula1.html#pacotes-no-r",
    "href": "Aula1.html#pacotes-no-r",
    "title": "Aula1",
    "section": "",
    "text": "Um pacote é um grupamento de funções, dados e arquivos que podem ser utilizados no R. Há milhares de pacotes que são desenvolvidos e disponibilizados em repositórios para download e que podem nos auxiliar em nosso trabalho.\n\n\nA instalação de pacotes pode ser feita pelo menu ou então com um comando no console. A instalação é feita através do menu em tools &gt; install packages e digitando o nome do pacote para baixar ou usando a função instal.packages(nome do pacote) no console.\nApós realizar a instalação do pacote, ele não estará disponível para uso imediatamente. Para habilitar o pacote para uso, se deve utilizar a função library(nome do pacote).\n\nlibrary(epifitter)"
  },
  {
    "objectID": "Aula1.html#objetos",
    "href": "Aula1.html#objetos",
    "title": "Aula1",
    "section": "",
    "text": "Um objeto é um nome que armazena um valor. Para criá-lo utilizamos &lt;- .\n\nx &lt;- 10\ny &lt;- x * 10\n\n\n\nPara criar um objeto que seja um conjunto de dados numéricos compreendidos em um intervalo, basta utilizar a função c(valor : valor).\n\na &lt;- c(1:10)\nb &lt;- c(11:20)"
  },
  {
    "objectID": "Aula1.html#data-frame",
    "href": "Aula1.html#data-frame",
    "title": "Aula1",
    "section": "",
    "text": "Um data-frame é uma estrutura para armazenar dados e é um objeto bidirecional. Ele pode conter uma mistura de diferentes tipos de dados, mas cada coluna deve ter o mesmo número de observações.\n\ndata.frame(pressure)\n\n   temperature pressure\n1            0   0.0002\n2           20   0.0012\n3           40   0.0060\n4           60   0.0300\n5           80   0.0900\n6          100   0.2700\n7          120   0.7500\n8          140   1.8500\n9          160   4.2000\n10         180   8.8000\n11         200  17.3000\n12         220  32.1000\n13         240  57.0000\n14         260  96.0000\n15         280 157.0000\n16         300 247.0000\n17         320 376.0000\n18         340 558.0000\n19         360 806.0000\n\ndf &lt;- data.frame(a,b)\n\ndf\n\n    a  b\n1   1 11\n2   2 12\n3   3 13\n4   4 14\n5   5 15\n6   6 16\n7   7 17\n8   8 18\n9   9 19\n10 10 20"
  },
  {
    "objectID": "Aula11.html",
    "href": "Aula11.html",
    "title": "Aula 11",
    "section": "",
    "text": "library(rnaturalearth)\nlibrary(remote)\n\nCarregando pacotes exigidos: Rcpp\n\n\nCarregando pacotes exigidos: raster\n\n\nCarregando pacotes exigidos: sp\n\nremotes::install_github(\"ropensci/rnaturalearthhires\")\n\nSkipping install of 'rnaturalearthhires' from a github remote, the SHA1 (dd1e210c) has not changed since last install.\n  Use `force = TRUE` to force installation\n\ninstall.packages(\"rnaturalearthhires\", repos = \"https://ropensci/rnaturalearthhires\")\n\nInstalling package into 'C:/Users/Windows/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository https://ropensci/rnaturalearthhires/src/contrib:\n  não foi possível abrir a URL 'https://ropensci/rnaturalearthhires/src/contrib/PACKAGES'\n\n\nWarning: package 'rnaturalearthhires' is not available for this version of R\n\nA version of this package for your version of R might be available elsewhere,\nsee the ideas at\nhttps://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages\n\n\nWarning: unable to access index for repository https://ropensci/rnaturalearthhires/bin/windows/contrib/4.3:\n  não foi possível abrir a URL 'https://ropensci/rnaturalearthhires/bin/windows/contrib/4.3/PACKAGES'\n\n\n\n\n\nPara plotar os paises utilizamos ne_countries() e para plotar os estados utilizamos ne_states()\n\nlibrary(rnaturalearthhires)\n\nBRA &lt;- ne_states(country = \"Brazil\",\n                 returnclass = \"sf\")\n\nword &lt;- ne_countries()\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::extract() masks raster::extract()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ dplyr::select()  masks raster::select()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nggplot(BRA) +\n  geom_sf(fill = \"white\",\n          color = \"green\",\n          linewidth = 1)\n\n\n\n\n\n\n\nPara retirar a grade do fundo utilizamos o theme_map.\n\nlibrary(r4pde)\n\nsbr &lt;- RustSoybean\n\nsbr |&gt; \n  ggplot(aes(longitude, latitude))+\n  geom_point()+\n  coord_sf()\n\n\n\nggplot(BRA)+\n  geom_sf(fill = \"white\",\n          color = \"yellow\",\n          linewidth = 1)+\n  geom_point(data = sbr, aes(longitude,latitude),\n             color = \"black\")\n\n\n\nlibrary(ggthemes)\n\nggplot(BRA)+\n  geom_sf(fill = \"white\",\n          color = \"yellow\",\n          linewidth = 1)+\n  geom_point(data = sbr, aes(longitude,latitude),\n             color = \"black\")+\n  theme_map()\n\n\n\n\n\n\n\n\nMG &lt;- BRA |&gt; \n  filter(name_en == \"Minas Gerais\")\n\nggplot(BRA)+\n  geom_sf(fill = \"white\",\n          color = \"yellow\",\n          linewidth = 1)+\n  geom_sf(data = MG, fill = \"green\")+\n  geom_point(data = sbr, aes(longitude,latitude), color = \"red\")+\n  theme_map()\n\n\n\n# Se quiser só os pontos e MG\nggplot(BRA)+\n    geom_sf(data = MG, fill = \"green\")+\n  geom_point(data = sbr, aes(longitude,latitude), color = \"red\")+\n  theme_map()\n\n\n\n\n\n\n\nUtilizamos annotation_north_arrow() para adicionar o posicionamento do norte no mapa.\n\nlibrary(ggspatial)\n\nbra &lt;- ggplot(BRA)+\n  geom_sf(fill = \"lightblue\",\n          color = \"black\",\n          linewidth = 0.1)+\n  geom_point(data = sbr, aes(longitude,latitude), color = \"darkblue\")+\n  theme_map()+\n  annotation_north_arrow()"
  },
  {
    "objectID": "Aula11.html#mapas-com-pontos-de-coordenadas",
    "href": "Aula11.html#mapas-com-pontos-de-coordenadas",
    "title": "Aula 11",
    "section": "",
    "text": "Para retirar a grade do fundo utilizamos o theme_map.\n\nlibrary(r4pde)\n\nsbr &lt;- RustSoybean\n\nsbr |&gt; \n  ggplot(aes(longitude, latitude))+\n  geom_point()+\n  coord_sf()\n\n\n\nggplot(BRA)+\n  geom_sf(fill = \"white\",\n          color = \"yellow\",\n          linewidth = 1)+\n  geom_point(data = sbr, aes(longitude,latitude),\n             color = \"black\")\n\n\n\nlibrary(ggthemes)\n\nggplot(BRA)+\n  geom_sf(fill = \"white\",\n          color = \"yellow\",\n          linewidth = 1)+\n  geom_point(data = sbr, aes(longitude,latitude),\n             color = \"black\")+\n  theme_map()"
  },
  {
    "objectID": "Aula11.html#selecionar-um-estado",
    "href": "Aula11.html#selecionar-um-estado",
    "title": "Aula 11",
    "section": "",
    "text": "MG &lt;- BRA |&gt; \n  filter(name_en == \"Minas Gerais\")\n\nggplot(BRA)+\n  geom_sf(fill = \"white\",\n          color = \"yellow\",\n          linewidth = 1)+\n  geom_sf(data = MG, fill = \"green\")+\n  geom_point(data = sbr, aes(longitude,latitude), color = \"red\")+\n  theme_map()\n\n\n\n# Se quiser só os pontos e MG\nggplot(BRA)+\n    geom_sf(data = MG, fill = \"green\")+\n  geom_point(data = sbr, aes(longitude,latitude), color = \"red\")+\n  theme_map()"
  },
  {
    "objectID": "Aula11.html#adicionar-rosa-dos-ventos",
    "href": "Aula11.html#adicionar-rosa-dos-ventos",
    "title": "Aula 11",
    "section": "",
    "text": "Utilizamos annotation_north_arrow() para adicionar o posicionamento do norte no mapa.\n\nlibrary(ggspatial)\n\nbra &lt;- ggplot(BRA)+\n  geom_sf(fill = \"lightblue\",\n          color = \"black\",\n          linewidth = 0.1)+\n  geom_point(data = sbr, aes(longitude,latitude), color = \"darkblue\")+\n  theme_map()+\n  annotation_north_arrow()"
  },
  {
    "objectID": "Aula11.html#personalização-do-mapa-interativo",
    "href": "Aula11.html#personalização-do-mapa-interativo",
    "title": "Aula 11",
    "section": "Personalização do mapa interativo",
    "text": "Personalização do mapa interativo\n\nlibrary(leaflet)\nleaflet() |&gt; \n  addTiles()\n\n\n\n\n# localização específica - Viçosa\nleaflet() |&gt; \n  addTiles() |&gt; \n  setView(lng = -42.8825, lat = -20.7546, zoom = 15) \n\n\n\n\n# Outro modelo\nleaflet() |&gt; \n  addProviderTiles(providers$Esri.NatGeoWorldMap) |&gt; \n  setView(lng = -42.8825, lat = -20.7546, zoom = 5) \n\n\n\n\n#Adicionando os pontos\nleaflet(sbr) |&gt; \n  addTiles() |&gt; \n  setView(lng = -42.8825, lat = -20.7546, zoom = 5) |&gt; \n  addCircleMarkers(radius = 1)\n\nAssuming \"longitude\" and \"latitude\" are longitude and latitude, respectively\n\n\n\n\n\nleaflet(sbr) |&gt; \n  addTiles() |&gt; \n  addCircleMarkers(radius = 1) \n\nAssuming \"longitude\" and \"latitude\" are longitude and latitude, respectively"
  },
  {
    "objectID": "Aula3.html",
    "href": "Aula3.html",
    "title": "Aula3",
    "section": "",
    "text": "Quando o conjunto de dados está em um arquivo csv na web, podemos utilizar a função read_csv(\"endereço na web\") para importar os dados para o programa.\n\nlibrary (tidyverse)\ncr &lt;- read_csv (\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\n\nglimpse(cr)\n\nRows: 405\nColumns: 13\n$ farm            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ region          &lt;chr&gt; \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", …\n$ zone            &lt;chr&gt; \"Bench Maji\", \"Bench Maji\", \"Bench Maji\", \"Bench Maji\"…\n$ district        &lt;chr&gt; \"Debub Bench\", \"Debub Bench\", \"Debub Bench\", \"Debub Be…\n$ lon             &lt;dbl&gt; 35.44250, 35.44250, 35.42861, 35.42861, 35.42861, 35.3…\n$ lat             &lt;dbl&gt; 6.904722, 6.904722, 6.904444, 6.904444, 6.904444, 6.90…\n$ altitude        &lt;dbl&gt; 1100, 1342, 1434, 1100, 1400, 1342, 1432, 1100, 1400, …\n$ cultivar        &lt;chr&gt; \"Local\", \"Mixture\", \"Mixture\", \"Local\", \"Local\", \"Mixt…\n$ shade           &lt;chr&gt; \"Sun\", \"Mid shade\", \"Mid shade\", \"Sun\", \"Sun\", \"Mid sh…\n$ cropping_system &lt;chr&gt; \"Plantation\", \"Plantation\", \"Plantation\", \"Plantation\"…\n$ farm_management &lt;chr&gt; \"Unmanaged\", \"Minimal\", \"Minimal\", \"Unmanaged\", \"Unman…\n$ inc             &lt;dbl&gt; 86.70805, 51.34354, 43.20000, 76.70805, 47.15808, 51.3…\n$ sev2            &lt;dbl&gt; 55.57986, 17.90349, 8.25120, 46.10154, 12.25167, 19.91…"
  },
  {
    "objectID": "Aula3.html#importando-os-dados",
    "href": "Aula3.html#importando-os-dados",
    "title": "Aula3",
    "section": "",
    "text": "Quando o conjunto de dados está em um arquivo csv na web, podemos utilizar a função read_csv(\"endereço na web\") para importar os dados para o programa.\n\nlibrary (tidyverse)\ncr &lt;- read_csv (\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\n\nglimpse(cr)\n\nRows: 405\nColumns: 13\n$ farm            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ region          &lt;chr&gt; \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", …\n$ zone            &lt;chr&gt; \"Bench Maji\", \"Bench Maji\", \"Bench Maji\", \"Bench Maji\"…\n$ district        &lt;chr&gt; \"Debub Bench\", \"Debub Bench\", \"Debub Bench\", \"Debub Be…\n$ lon             &lt;dbl&gt; 35.44250, 35.44250, 35.42861, 35.42861, 35.42861, 35.3…\n$ lat             &lt;dbl&gt; 6.904722, 6.904722, 6.904444, 6.904444, 6.904444, 6.90…\n$ altitude        &lt;dbl&gt; 1100, 1342, 1434, 1100, 1400, 1342, 1432, 1100, 1400, …\n$ cultivar        &lt;chr&gt; \"Local\", \"Mixture\", \"Mixture\", \"Local\", \"Local\", \"Mixt…\n$ shade           &lt;chr&gt; \"Sun\", \"Mid shade\", \"Mid shade\", \"Sun\", \"Sun\", \"Mid sh…\n$ cropping_system &lt;chr&gt; \"Plantation\", \"Plantation\", \"Plantation\", \"Plantation\"…\n$ farm_management &lt;chr&gt; \"Unmanaged\", \"Minimal\", \"Minimal\", \"Unmanaged\", \"Unman…\n$ inc             &lt;dbl&gt; 86.70805, 51.34354, 43.20000, 76.70805, 47.15808, 51.3…\n$ sev2            &lt;dbl&gt; 55.57986, 17.90349, 8.25120, 46.10154, 12.25167, 19.91…"
  },
  {
    "objectID": "Aula3.html#personalização-da-visualização-dos-dados",
    "href": "Aula3.html#personalização-da-visualização-dos-dados",
    "title": "Aula3",
    "section": "Personalização da Visualização dos dados",
    "text": "Personalização da Visualização dos dados\nO pacote ggthemes apresenta diversos temas que podem ser utilizados para personalizar os gráficos, bem como possibilidades de personalização dos elementos gráficos.\nPodemos utilizar scale_fill_colorblind() para uma coloração pré-definida para as colunas ou adicionar manualmente as cores desejadas com scale_fill_manual(). Podemos adicionar um tema como, por exemplo, theme_minimal() e adicionar anotações com a função labs().\n\nlibrary(ggthemes)\n\ncr %&gt;%  \nggplot (aes(x = sev2, fill = region))+\ngeom_histogram()+\nfacet_grid(region ~ cultivar)+\nscale_fill_colorblind()\n\n\n\ncr %&gt;% \nggplot (aes(x = sev2, fill = region))+\ngeom_histogram()+\nfacet_grid(region ~ cultivar)+ \nscale_fill_manual(values = c(\"red\",\"blue\"))+\ntheme_minimal(base_size = 14)+\ntheme(legend.position = \"bottom\")+\nlabs (y= \"frequency\", \n     x= \"severity (%)\", fill = \"region\")\n\n\n\ncr %&gt;% \nggplot (aes(x = sev2, fill = region))+\ngeom_histogram(color = \"white\") +\nfacet_grid(region ~ cultivar)+ \nscale_fill_manual(values = c(\"red\",\"blue\"))+\ntheme_minimal(base_size = 14)+\ntheme(legend.position = \"bottom\")+\nlabs (y= \"frequency\", \n     x= \"severity (%)\", fill = \"region\")"
  },
  {
    "objectID": "Aula3.html#visualização-dos-subconjuntos",
    "href": "Aula3.html#visualização-dos-subconjuntos",
    "title": "Aula3",
    "section": "Visualização dos subconjuntos",
    "text": "Visualização dos subconjuntos\nCriação de gráficos boxplot para cada subconjunto.\n\np1 &lt;- cr_oromia %&gt;% \n  ggplot(aes(cultivar,sev2, fill = cultivar))+ \n  geom_boxplot()+\n  theme_few()+\n  scale_fill_few()+\n  labs(x = \"\", \n       y= \"Severity (%)\") +\n  coord_flip()\n\n\np2 &lt;- cr_pr %&gt;% \n  ggplot(aes(cultivar,sev2, fill = cultivar))+ \n  geom_boxplot()+\n  theme_few()+\n  scale_fill_few()+\n  labs(x= \"\", \n       y= \"Severity(%)\") +\ncoord_flip()"
  },
  {
    "objectID": "Aula3.html#juntar-os-gráficos-em-diferentes-posicionamntos",
    "href": "Aula3.html#juntar-os-gráficos-em-diferentes-posicionamntos",
    "title": "Aula3",
    "section": "Juntar os gráficos em diferentes posicionamntos",
    "text": "Juntar os gráficos em diferentes posicionamntos\nPara juntar diferentes gráficos em uma mesma imagem podemos utilizar o pacote patchwork. Para posicionamento ao lado utilizamos “+” e para posicionamento de um acima ao outro utilizamos “/”.\n\nlibrary(patchwork)\n\n# Ao lado\np1 + p2\n\n\n\n# Acima \np1 / p2\n\n\n\n\nPara retirar a legenda dplicada devemos adicionar plot_layout(guides = \"collect\"). E para atribuir letras a cada gráfico utilizamos plot_annotation(tag_levels = \"A\").\n\n# Retirar a legenda duplicada\n(p1 + p2) +\n  plot_layout(guides = \"collect\")\n\n\n\n# Atribuir letras a cada gráfico\n(p1 / p2) +\n  plot_layout(guides = \"collect\") +\n  plot_annotation(tag_levels = \"A\")\n\n\n\n\nPara salvar o gráfico, utilizamos a função ggsave().\n\nggsave(\"patch1.png\", width = 5, \n       height = 4)\n\nPara retirar a duplicação de cultivar e severidade nos graficos adicionamos axes = \"collect\"\n\n(p1 / p2) +\nplot_layout(guides = \"collect\",\n            axes = \"collect\" ) +\n  plot_annotation(tag_levels = \"A\")\n\n\n\n\nPara atribuir um título geral e fonte aos gráficos, adicionamos plot_annotation(title = \"Título\", caption = \"fonte\".\n\n(p1 / p2) +\nplot_layout(guides = \"collect\",\n            axes = \"collect\" ) +\n  plot_annotation(title = \"Coffee rust in Ethiopia\",\n                  caption = \"source: Del Ponte(2022)\"\n                  ,tag_levels = \"A\")"
  },
  {
    "objectID": "Aula3.html#adicionar-um-gráfico-em-um-determinado-posicionamento-de-um-outro-gráfico",
    "href": "Aula3.html#adicionar-um-gráfico-em-um-determinado-posicionamento-de-um-outro-gráfico",
    "title": "Aula3",
    "section": "Adicionar um gráfico em um determinado posicionamento de um outro gráfico",
    "text": "Adicionar um gráfico em um determinado posicionamento de um outro gráfico\nPara adicionar um gráfico ou elemento a outro gráfico em um posicionamento próprio, utilizamos a função inset_element().\n\np3 &lt;- cr_oromia %&gt;% \n  ggplot(aes(x=sev2))+\n  geom_histogram()\n\np1 + inset_element (p3, left = 0.6, bottom = 0.6, right = 1, top = 1)"
  },
  {
    "objectID": "Aula5.html",
    "href": "Aula5.html",
    "title": "Aula5",
    "section": "",
    "text": "O documento tem por objtivo descrever e ilustrar o desempenho geral dos estudantes matriculados na disciplina FIP606\n\n\nPara importar os dados que iremos trabalhar diretamente da tabela google, devemos utilizar o pacote gsheet e a função gsheet2tb1.\n\nlibrary(gsheet)\nsab &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1092065531\")\n\n\n\n\nPara separar os dados da primeira e da segunda sabatina, devemos filtrar os dados e criar subconjuntos. Utilizaremos a função filter e criaremos um objeto para cada grupo de dados.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nprova1 &lt;- sab %&gt;% \n  filter(prova == 1)\n\nprova2 &lt;- sab %&gt;% \n  filter(prova == 2)\n\n\n\n\nPara obtermos valores de tendência central e dispersão do conjunto de dados, utilizaremos a função summarise para obter os valores de máximo, mínimo, a média amostral, a mediana e o desvio padrão em cada sabatina.\n\nsab %&gt;% \n  group_by(prova) %&gt;% \n  summarise(nota_mean = mean(nota),nota_med = median(nota), sd_mean = sd(nota), nota_max = max(nota), min_nota = min(nota))\n\n# A tibble: 2 × 6\n  prova nota_mean nota_med sd_mean nota_max min_nota\n  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1     1      79.5     85.7    19.0      100     42.9\n2     2      79.3     84.4    19.7      100     43.8\n\n\nA média das notas obtidas pelos alunos na sabatina 1 foi de 79,55 e os valores variaram entre 42,90 e 100,00. Os valores encontrados na sabatina 2 foram semelhantes, em que a média amostral foi de 79,26 e os valores variaram entre 43,75 e 100. O desvio padrão de ambas as provas também foi semelhante com valor de 19,00 e 19,71, na primeira e segunda sabatina respectivamente.\n\n\n\nPara uma análise exploratória inicial e visualização dos dados, utilizarmos o pacote ggplot2 para criarmos diferentes gráficos com os conjuntos de dados.\n\nlibrary (ggplot2)\n\nprova1 %&gt;% \n  ggplot(aes(nota)) + geom_histogram() +\n  facet_wrap(~prova) +\n  theme_bw() \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nprova2 %&gt;% \n  ggplot(aes(nota)) + geom_histogram() +\n  facet_wrap(~prova) +\n  theme_bw() \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nsab %&gt;% \n  ggplot(aes(x = prova , y = nota)) + geom_jitter() +\n  theme_bw()\n\n\n\nprova1 %&gt;% \n  ggplot(aes(prova, nota)) + \n  geom_boxplot()\n\n\n\nprova2 %&gt;% \n  ggplot(aes(prova, nota)) + \n  geom_boxplot()\n\n\n\n\n\n\n\nPara modificarmos a aparência dos gráficos e demonstrar os dados de forma mais didática e com um maior número de informações, customizaremos o script do desenvolvimento dos gráficos do tipo histograma e boxplot.\n\nlibrary (ggthemes)\n\n#gráficos histograma\npv1 &lt;- prova1 %&gt;% \n  ggplot(aes(nota)) + geom_histogram(bins = 5,fill = \"darkgreen\", color = \"white\", ) +\n  theme_bw() +\n  labs( title= \"Prova 1\",\n        y = \"Frequency\",\n        x = \"Nota\") + \n  ylim (0,10) +\n  geom_vline(xintercept = 79.54545, linetype = \"dashed\") +\n  annotate(geom = \"text\",\n           x = 79, y = 9.5,\n           label = \"Mean\")\n  \n  \n\npv2 &lt;- prova2 %&gt;% \n  ggplot(aes(nota)) + geom_histogram(bins = 5, fill = \"darkblue\", color = \"white\",) +\n  theme_bw() +\n  labs( title = \"Prova 2\",\n        y = \"Frequency\",\n        x = \"Nota\") +\n  ylim (0,10) +\n  geom_vline(xintercept = 79.26136, linetype = \"dashed\") +\n   annotate(geom = \"text\",\n           x = 79, y = 9.5,\n           label = \"Mean\")\n\n\n#gráficos boxplot\n\npv12 &lt;- prova1 %&gt;% \n  ggplot(aes(nota, prova)) + \n  geom_boxplot(fill = \"lightblue\") +\n  geom_jitter() +\n  coord_flip() +\n  theme_few() +\n  labs (x = \"Notas\",\n        y = \"Prova 1\")\n\npv22 &lt;- prova2 %&gt;% \n  ggplot(aes(nota, prova)) + \n  geom_boxplot(fill = \"lightblue\") +\n  geom_jitter() +\n  coord_flip() +\n  theme_few() +\n  labs (x = \"Notas\",\n        y = \"Prova 2\")\n\n\n\n\nPara obter os dois gráficos gerados de cada formato em apenas uma imagem, utilizaremos o pacote patchork.\n\nlibrary (patchwork)\n\n(pv1 + pv2) +\n    plot_layout(guides = \"collect\", \n              axes = \"collect\")\n\n\n\n\nPodemos observar, pelos gráficos do tipo histograma, que a distribuição das notas dos alunos não apresenta uma distribuição normal.\n\n(pv12 + pv22) +\n  plot_layout(guides = \"collect\", \n              axes = \"collect\") \n\n\n\n\nPodemos observar, pelo gráfico do tipo boxplot, que a mediana das notas de cada sabatina foram próximas e que a maioria das notas alcançaram o mínimo de 60 pontos.\n\n\n\nPara visualizar a variabilidade do conjunto de dados, podemos utilizar uma barra de erro da média amostral em relação ao desvio padrão\n\nsab %&gt;% \n  group_by(prova) %&gt;% \n  summarise(nota_mean = mean(nota),\n            nota_sd = sd(nota)) %&gt;% \n  ggplot(aes(factor(prova), nota_mean)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = nota_mean - nota_sd,\n                    ymax = nota_mean + nota_sd), \n                width = 0.1) +\n  ylim(0,100) +\n  labs (x = \"Prova\",\n        y = \"Nota\")\n\n\n\n\nPelo gráfico de barra de erro, podemos perceber que houve uma elevada variabilidade em ambos conjuntos de dados e que esse erro foi similar em ambas sabatinas."
  },
  {
    "objectID": "Aula5.html#importando-os-dados",
    "href": "Aula5.html#importando-os-dados",
    "title": "Aula5",
    "section": "",
    "text": "Para importar os dados que iremos trabalhar diretamente da tabela google, devemos utilizar o pacote gsheet e a função gsheet2tb1.\n\nlibrary(gsheet)\nsab &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1092065531\")"
  },
  {
    "objectID": "Aula5.html#criando-subgrupos",
    "href": "Aula5.html#criando-subgrupos",
    "title": "Aula5",
    "section": "",
    "text": "Para separar os dados da primeira e da segunda sabatina, devemos filtrar os dados e criar subconjuntos. Utilizaremos a função filter e criaremos um objeto para cada grupo de dados.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nprova1 &lt;- sab %&gt;% \n  filter(prova == 1)\n\nprova2 &lt;- sab %&gt;% \n  filter(prova == 2)"
  },
  {
    "objectID": "Aula5.html#sumarizando-os-dados",
    "href": "Aula5.html#sumarizando-os-dados",
    "title": "Aula5",
    "section": "",
    "text": "Para obtermos valores de tendência central e dispersão do conjunto de dados, utilizaremos a função summarise para obter os valores de máximo, mínimo, a média amostral, a mediana e o desvio padrão em cada sabatina.\n\nsab %&gt;% \n  group_by(prova) %&gt;% \n  summarise(nota_mean = mean(nota),nota_med = median(nota), sd_mean = sd(nota), nota_max = max(nota), min_nota = min(nota))\n\n# A tibble: 2 × 6\n  prova nota_mean nota_med sd_mean nota_max min_nota\n  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1     1      79.5     85.7    19.0      100     42.9\n2     2      79.3     84.4    19.7      100     43.8\n\n\nA média das notas obtidas pelos alunos na sabatina 1 foi de 79,55 e os valores variaram entre 42,90 e 100,00. Os valores encontrados na sabatina 2 foram semelhantes, em que a média amostral foi de 79,26 e os valores variaram entre 43,75 e 100. O desvio padrão de ambas as provas também foi semelhante com valor de 19,00 e 19,71, na primeira e segunda sabatina respectivamente."
  },
  {
    "objectID": "Aula5.html#explorando-os-dados",
    "href": "Aula5.html#explorando-os-dados",
    "title": "Aula5",
    "section": "",
    "text": "Para uma análise exploratória inicial e visualização dos dados, utilizarmos o pacote ggplot2 para criarmos diferentes gráficos com os conjuntos de dados.\n\nlibrary (ggplot2)\n\nprova1 %&gt;% \n  ggplot(aes(nota)) + geom_histogram() +\n  facet_wrap(~prova) +\n  theme_bw() \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nprova2 %&gt;% \n  ggplot(aes(nota)) + geom_histogram() +\n  facet_wrap(~prova) +\n  theme_bw() \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nsab %&gt;% \n  ggplot(aes(x = prova , y = nota)) + geom_jitter() +\n  theme_bw()\n\n\n\nprova1 %&gt;% \n  ggplot(aes(prova, nota)) + \n  geom_boxplot()\n\n\n\nprova2 %&gt;% \n  ggplot(aes(prova, nota)) + \n  geom_boxplot()"
  },
  {
    "objectID": "Aula5.html#customizando-os-gráficos",
    "href": "Aula5.html#customizando-os-gráficos",
    "title": "Aula5",
    "section": "",
    "text": "Para modificarmos a aparência dos gráficos e demonstrar os dados de forma mais didática e com um maior número de informações, customizaremos o script do desenvolvimento dos gráficos do tipo histograma e boxplot.\n\nlibrary (ggthemes)\n\n#gráficos histograma\npv1 &lt;- prova1 %&gt;% \n  ggplot(aes(nota)) + geom_histogram(bins = 5,fill = \"darkgreen\", color = \"white\", ) +\n  theme_bw() +\n  labs( title= \"Prova 1\",\n        y = \"Frequency\",\n        x = \"Nota\") + \n  ylim (0,10) +\n  geom_vline(xintercept = 79.54545, linetype = \"dashed\") +\n  annotate(geom = \"text\",\n           x = 79, y = 9.5,\n           label = \"Mean\")\n  \n  \n\npv2 &lt;- prova2 %&gt;% \n  ggplot(aes(nota)) + geom_histogram(bins = 5, fill = \"darkblue\", color = \"white\",) +\n  theme_bw() +\n  labs( title = \"Prova 2\",\n        y = \"Frequency\",\n        x = \"Nota\") +\n  ylim (0,10) +\n  geom_vline(xintercept = 79.26136, linetype = \"dashed\") +\n   annotate(geom = \"text\",\n           x = 79, y = 9.5,\n           label = \"Mean\")\n\n\n#gráficos boxplot\n\npv12 &lt;- prova1 %&gt;% \n  ggplot(aes(nota, prova)) + \n  geom_boxplot(fill = \"lightblue\") +\n  geom_jitter() +\n  coord_flip() +\n  theme_few() +\n  labs (x = \"Notas\",\n        y = \"Prova 1\")\n\npv22 &lt;- prova2 %&gt;% \n  ggplot(aes(nota, prova)) + \n  geom_boxplot(fill = \"lightblue\") +\n  geom_jitter() +\n  coord_flip() +\n  theme_few() +\n  labs (x = \"Notas\",\n        y = \"Prova 2\")"
  },
  {
    "objectID": "Aula5.html#juntando-os-gráficos",
    "href": "Aula5.html#juntando-os-gráficos",
    "title": "Aula5",
    "section": "",
    "text": "Para obter os dois gráficos gerados de cada formato em apenas uma imagem, utilizaremos o pacote patchork.\n\nlibrary (patchwork)\n\n(pv1 + pv2) +\n    plot_layout(guides = \"collect\", \n              axes = \"collect\")\n\n\n\n\nPodemos observar, pelos gráficos do tipo histograma, que a distribuição das notas dos alunos não apresenta uma distribuição normal.\n\n(pv12 + pv22) +\n  plot_layout(guides = \"collect\", \n              axes = \"collect\") \n\n\n\n\nPodemos observar, pelo gráfico do tipo boxplot, que a mediana das notas de cada sabatina foram próximas e que a maioria das notas alcançaram o mínimo de 60 pontos."
  },
  {
    "objectID": "Aula5.html#gráfico-de-barras-de-erro",
    "href": "Aula5.html#gráfico-de-barras-de-erro",
    "title": "Aula5",
    "section": "",
    "text": "Para visualizar a variabilidade do conjunto de dados, podemos utilizar uma barra de erro da média amostral em relação ao desvio padrão\n\nsab %&gt;% \n  group_by(prova) %&gt;% \n  summarise(nota_mean = mean(nota),\n            nota_sd = sd(nota)) %&gt;% \n  ggplot(aes(factor(prova), nota_mean)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = nota_mean - nota_sd,\n                    ymax = nota_mean + nota_sd), \n                width = 0.1) +\n  ylim(0,100) +\n  labs (x = \"Prova\",\n        y = \"Nota\")\n\n\n\n\nPelo gráfico de barra de erro, podemos perceber que houve uma elevada variabilidade em ambos conjuntos de dados e que esse erro foi similar em ambas sabatinas."
  },
  {
    "objectID": "Aula7.html",
    "href": "Aula7.html",
    "title": "Aula 7",
    "section": "",
    "text": "Utilizando um conjunto de dados disponível no pacote nativo do programa\n\ninseticida &lt;- InsectSprays\n?InsectSprays\n\nstarting httpd help server ... done\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ninseticida %&gt;% \n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12\n\n\nO conjunto apresenta um fator com seis niveis"
  },
  {
    "objectID": "Aula7.html#conjunto-de-dados",
    "href": "Aula7.html#conjunto-de-dados",
    "title": "Aula 7",
    "section": "",
    "text": "Utilizando um conjunto de dados disponível no pacote nativo do programa\n\ninseticida &lt;- InsectSprays\n?InsectSprays\n\nstarting httpd help server ... done\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ninseticida %&gt;% \n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12\n\n\nO conjunto apresenta um fator com seis niveis"
  },
  {
    "objectID": "Aula7.html#visualização-inicial",
    "href": "Aula7.html#visualização-inicial",
    "title": "Aula 7",
    "section": "Visualização inicial",
    "text": "Visualização inicial\n\ninseticida %&gt;% \n  ggplot(aes(spray,count)) +\n  geom_boxplot()"
  },
  {
    "objectID": "Aula7.html#anova",
    "href": "Aula7.html#anova",
    "title": "Aula 7",
    "section": "Anova",
    "text": "Anova\n\nm1 &lt;- lm (count ~ spray, data = inseticida)\n\nanova (m1)\n\nAnalysis of Variance Table\n\nResponse: count\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 2668.8  533.77  34.702 &lt; 2.2e-16 ***\nResiduals 66 1015.2   15.38                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m1)\n\n\nCall:\nlm(formula = count ~ spray, data = inseticida)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.333 -1.958 -0.500  1.667  9.333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  14.5000     1.1322  12.807  &lt; 2e-16 ***\nsprayB        0.8333     1.6011   0.520    0.604    \nsprayC      -12.4167     1.6011  -7.755 7.27e-11 ***\nsprayD       -9.5833     1.6011  -5.985 9.82e-08 ***\nsprayE      -11.0000     1.6011  -6.870 2.75e-09 ***\nsprayF        2.1667     1.6011   1.353    0.181    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.922 on 66 degrees of freedom\nMultiple R-squared:  0.7244,    Adjusted R-squared:  0.7036 \nF-statistic:  34.7 on 5 and 66 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Aula7.html#verificação-das-premissas",
    "href": "Aula7.html#verificação-das-premissas",
    "title": "Aula 7",
    "section": "Verificação das premissas",
    "text": "Verificação das premissas\n\nm1$residuals\n\n          1           2           3           4           5           6 \n-4.50000000 -7.50000000  5.50000000 -0.50000000 -0.50000000 -2.50000000 \n          7           8           9          10          11          12 \n-4.50000000  8.50000000  2.50000000  5.50000000 -0.50000000 -1.50000000 \n         13          14          15          16          17          18 \n-4.33333333  1.66666667  5.66666667 -4.33333333  0.66666667 -1.33333333 \n         19          20          21          22          23          24 \n 1.66666667  1.66666667  3.66666667  5.66666667 -8.33333333 -2.33333333 \n         25          26          27          28          29          30 \n-2.08333333 -1.08333333  4.91666667 -0.08333333  0.91666667 -1.08333333 \n         31          32          33          34          35          36 \n-0.08333333 -1.08333333  0.91666667 -2.08333333 -1.08333333  1.91666667 \n         37          38          39          40          41          42 \n-1.91666667  0.08333333  7.08333333  1.08333333 -0.91666667 -1.91666667 \n         43          44          45          46          47          48 \n 0.08333333  0.08333333  0.08333333  0.08333333 -2.91666667 -0.91666667 \n         49          50          51          52          53          54 \n-0.50000000  1.50000000 -0.50000000  1.50000000 -0.50000000  2.50000000 \n         55          56          57          58          59          60 \n-2.50000000 -2.50000000 -0.50000000 -1.50000000  2.50000000  0.50000000 \n         61          62          63          64          65          66 \n-5.66666667 -7.66666667 -1.66666667  5.33333333 -1.66666667 -0.66666667 \n         67          68          69          70          71          72 \n-3.66666667 -6.66666667  9.33333333  9.33333333  7.33333333 -3.66666667 \n\nhist(m1$residuals)\n\n\n\nqqnorm(m1$residuals)\nqqline(m1$residuals)\n\n\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.96006, p-value = 0.02226\n\nbartlett.test(count ~ spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count by spray\nBartlett's K-squared = 25.96, df = 5, p-value = 9.085e-05\n\nlibrary(performance)\ncheck_normality(m1)\n\nWarning: Non-normality of residuals detected (p = 0.022).\n\ncheck_heteroscedasticity(m1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\nlibrary(DHARMa)\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(m1))\n\n\n\n\nQuando há variânças heterogênas é mais problemático, normalidade pode relevar um pouco e proceder com a análise a depender do caso. Mas o conjunto de dados acima tem ambos os problemas, então deve utilizar alternativas de avaliação como a transformação do conjunto de dados."
  },
  {
    "objectID": "Aula7.html#transformação-do-conjunto-de-dados",
    "href": "Aula7.html#transformação-do-conjunto-de-dados",
    "title": "Aula 7",
    "section": "Transformação do conjunto de dados",
    "text": "Transformação do conjunto de dados\nPodemos transformar os dados de diferentes maneiras, sendo as mais comuns log e raiz quadrada. O conjunto inseticida apresenta variáveis resposta do tipo númerica discreta e, normalmente, a transformação para raiz quadrada é uma boa opção. Para a transformação utilizamos a função mutate() e o argumento sqrt().\n\ninseticida &lt;- inseticida %&gt;% \n  mutate(count2 = sqrt(count))"
  },
  {
    "objectID": "Aula7.html#anova-e-verificação-das-premissas-com-o-conjunto-transformado",
    "href": "Aula7.html#anova-e-verificação-das-premissas-com-o-conjunto-transformado",
    "title": "Aula 7",
    "section": "Anova e verificação das premissas com o conjunto transformado",
    "text": "Anova e verificação das premissas com o conjunto transformado\n\nm2 &lt;- lm (count2 ~ spray,\n          data = inseticida)\nanova(m2)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m2)\n\n\nCall:\nlm(formula = count2 ~ spray, data = inseticida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24486 -0.39970 -0.01902  0.42661  1.40089 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.7607     0.1814  20.733  &lt; 2e-16 ***\nsprayB        0.1160     0.2565   0.452    0.653    \nsprayC       -2.5158     0.2565  -9.807 1.64e-14 ***\nsprayD       -1.5963     0.2565  -6.223 3.80e-08 ***\nsprayE       -1.9512     0.2565  -7.606 1.34e-10 ***\nsprayF        0.2579     0.2565   1.006    0.318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6283 on 66 degrees of freedom\nMultiple R-squared:  0.7724,    Adjusted R-squared:  0.7552 \nF-statistic:  44.8 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nm2$residuals\n\n          1           2           3           4           5           6 \n-0.59840073 -1.11492708  0.71145756 -0.01902101 -0.01902101 -0.29657678 \n          7           8           9          10          11          12 \n-0.59840073  1.03515313  0.36242723  0.71145756 -0.01902101 -0.15512712 \n         13          14          15          16          17          18 \n-0.56000661  0.24647423  0.70594430 -0.56000661  0.12336860 -0.13497401 \n         19          20          21          22          23          24 \n 0.24647423  0.24647423  0.48226755  0.70594430 -1.23088009 -0.27108012 \n         25          26          27          28          29          30 \n-1.24485667 -0.24485667  1.40089464  0.16935689  0.48719414 -0.24485667 \n         31          32          33          34          35          36 \n 0.16935689 -0.24485667  0.48719414 -1.24485667 -0.24485667  0.75514333 \n         37          38          39          40          41          42 \n-0.43230306  0.07171411  1.29974775  0.28513587 -0.16435387 -0.43230306 \n         43          44          45          46          47          48 \n 0.07171411  0.07171411  0.07171411  0.07171411 -0.75014031 -0.16435387 \n         49          50          51          52          53          54 \n-0.07741021  0.42660696 -0.07741021  0.42660696 -0.07741021  0.64002872 \n         55          56          57          58          59          60 \n-0.80946102 -0.80946102 -0.07741021 -0.39524746  0.64002872  0.19053898 \n         61          62          63          64          65          66 \n-0.70199237 -1.01861716 -0.14563382  0.67179860 -0.14563382 -0.01861716 \n         67          68          69          70          71          72 \n-0.41306589 -0.85633950  1.08040235  1.08040235  0.88036232 -0.41306589 \n\nhist(m2$residuals)\n\n\n\nqqnorm(m2$residuals)\nqqline(m2$residuals)\n\n\n\nshapiro.test(m2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98721, p-value = 0.6814\n\nbartlett.test(count2 ~ spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count2 by spray\nBartlett's K-squared = 3.7525, df = 5, p-value = 0.5856\n\nlibrary(performance)\ncheck_normality(m2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\nlibrary(DHARMa)\nplot(simulateResiduals(m2))\n\n\n\n\n\nTransformação box-cox\nA transformação tipo Box-Cox é utilizada para melhorar a adequação dos dados aos pressupostos de normalidade e homogeneidade de variância. A transformação de Box-Cox é definida pela seguinte equação: y(lambda) = (x^lambda - 1) / lambda. Para encontrar o valor de lambda (valor de x quando y é maximo) utilizamos o pacote MASS\n\nlibrary(MASS)\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\nB &lt;- boxcox(lm(inseticida$count+0.1 ~ 1))\n\n\n\nlambda &lt;- B$x[which.max(B$y)]\nlambda \n\n[1] 0.4242424\n\ninseticida$count3 &lt;- (inseticida$count ^ lambda - 1) / lambda\ninseticida$count3 \n\n [1]  3.903635  3.024469  6.043993  4.864268  4.864268  4.407118  3.903635\n [8]  6.557185  5.484274  6.043993  4.864268  4.640760  4.161975  5.484274\n[15]  6.219699  4.161975  5.285168  4.864268  5.484274  5.484274  5.863153\n[22]  6.219699  3.024469  4.640760 -2.357143  0.000000  3.024469  0.805831\n[29]  1.399509  0.000000  0.805831  0.000000  1.399509 -2.357143  0.000000\n[36]  1.887150  1.399509  2.308577  4.407118  2.683787  1.887150  1.399509\n[43]  2.308577  2.308577  2.308577  2.308577  0.805831  1.887150  1.399509\n[50]  2.308577  1.399509  2.308577  1.399509  2.683787  0.000000  0.000000\n[57]  1.399509  0.805831  2.683787  1.887150  4.161975  3.629951  5.078760\n[64]  6.390651  5.078760  5.285168  4.640760  3.903635  7.033117  7.033117\n[71]  6.719601  4.640760"
  },
  {
    "objectID": "Aula7.html#discriminação-dos-tratamentos-com-médias-distintas-estatisticamente",
    "href": "Aula7.html#discriminação-dos-tratamentos-com-médias-distintas-estatisticamente",
    "title": "Aula 7",
    "section": "Discriminação dos tratamentos com médias distintas estatisticamente",
    "text": "Discriminação dos tratamentos com médias distintas estatisticamente\nAvaliação com o conjunto de dados original e os dados transformados para comparação de discriminação dos grupos.\n\nlibrary(emmeans)\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\nm1_medias &lt;- emmeans(m1, ~ spray)\nplot(m1_medias)\n\n\n\nlibrary(multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nCarregando pacotes exigidos: TH.data\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\ncld(m1_medias)\n\n spray emmean   SE df lower.CL upper.CL .group\n C       2.08 1.13 66   -0.177     4.34  1    \n E       3.50 1.13 66    1.240     5.76  1    \n D       4.92 1.13 66    2.656     7.18  1    \n A      14.50 1.13 66   12.240    16.76   2   \n B      15.33 1.13 66   13.073    17.59   2   \n F      16.67 1.13 66   14.406    18.93   2   \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nlibrary(emmeans)\nm2_medias &lt;- emmeans(m2, ~ spray)\nlibrary(multcomp)\nplot(m2_medias)\n\n\n\ncld(m2_medias)\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n#matriz de comparação\npwpm(m2_medias)\n\n       A      B      C      D      E      F\nA [3.76] 0.9975 &lt;.0001 &lt;.0001 &lt;.0001 0.9145\nB -0.116 [3.88] &lt;.0001 &lt;.0001 &lt;.0001 0.9936\nC  2.516  2.632 [1.24] 0.0081 0.2513 &lt;.0001\nD  1.596  1.712 -0.919 [2.16] 0.7366 &lt;.0001\nE  1.951  2.067 -0.565  0.355 [1.81] &lt;.0001\nF -0.258 -0.142 -2.774 -1.854 -2.209 [4.02]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\n#representação gráfica\npwpp(m2_medias)\n\n\n\n#comparação par a par\npairs(m2_medias)\n\n contrast estimate    SE df t.ratio p.value\n A - B      -0.116 0.257 66  -0.452  0.9975\n A - C       2.516 0.257 66   9.807  &lt;.0001\n A - D       1.596 0.257 66   6.223  &lt;.0001\n A - E       1.951 0.257 66   7.606  &lt;.0001\n A - F      -0.258 0.257 66  -1.006  0.9145\n B - C       2.632 0.257 66  10.259  &lt;.0001\n B - D       1.712 0.257 66   6.675  &lt;.0001\n B - E       2.067 0.257 66   8.058  &lt;.0001\n B - F      -0.142 0.257 66  -0.554  0.9936\n C - D      -0.919 0.257 66  -3.584  0.0081\n C - E      -0.565 0.257 66  -2.201  0.2513\n C - F      -2.774 0.257 66 -10.813  &lt;.0001\n D - E       0.355 0.257 66   1.383  0.7366\n D - F      -1.854 0.257 66  -7.229  &lt;.0001\n E - F      -2.209 0.257 66  -8.612  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\nModelo sem transformação discriminou menos, houve o erro tipo 2 (não rejeitou a hipótese nula quando deveria)."
  },
  {
    "objectID": "Aula7.html#estatística-não-paramétrica",
    "href": "Aula7.html#estatística-não-paramétrica",
    "title": "Aula 7",
    "section": "Estatística não paramétrica",
    "text": "Estatística não paramétrica\nO teste Kruskal é o equivalente não paramétrico da ANOVA. Para realizar a análise é utilizada a função kruskal.test().\n\nkruskal.test(count ~ spray,\n             data = inseticida)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\nlibrary(agricolae)\n\nm3 &lt;- kruskal(inseticida$count,\n        inseticida$spray,\n        group = TRUE)\n\nm3\n\n$statistics\n     Chisq Df      p.chisq  t.value      MSD\n  54.69134  5 1.510845e-10 1.996564 8.462804\n\n$parameters\n            test p.ajusted           name.t ntr alpha\n  Kruskal-Wallis      none inseticida$spray   6  0.05\n\n$means\n  inseticida.count     rank      std  r Min Max   Q25  Q50   Q75\nA        14.500000 52.16667 4.719399 12   7  23 11.50 14.0 17.75\nB        15.333333 54.83333 4.271115 12   7  21 12.50 16.5 17.50\nC         2.083333 11.45833 1.975225 12   0   7  1.00  1.5  3.00\nD         4.916667 25.58333 2.503028 12   2  12  3.75  5.0  5.00\nE         3.500000 19.33333 1.732051 12   1   6  2.75  3.0  5.00\nF        16.666667 55.62500 6.213378 12   9  26 12.50 15.0 22.50\n\n$comparison\nNULL\n\n$groups\n  inseticida$count groups\nF         55.62500      a\nB         54.83333      a\nA         52.16667      a\nD         25.58333      b\nE         19.33333     bc\nC         11.45833      c\n\nattr(,\"class\")\n[1] \"group\""
  },
  {
    "objectID": "Aula7.html#modelo-fatorial-two-way-anova",
    "href": "Aula7.html#modelo-fatorial-two-way-anova",
    "title": "Aula 7",
    "section": "Modelo fatorial (two-way ANOVA)",
    "text": "Modelo fatorial (two-way ANOVA)\nNa two-way ANOVA devemos utilizar “fator1*fator2” no modelo estatístico.\n\nmf &lt;- lm (severity ~ treat*factor(dose),\n          data = li)\nmf\n\n\nCall:\nlm(formula = severity ~ treat * factor(dose), data = li)\n\nCoefficients:\n                    (Intercept)                treatTebuconazole  \n                         0.2921                          -0.2711  \n                  factor(dose)2  treatTebuconazole:factor(dose)2  \n                        -0.2420                           0.2412  \n\nanova(mf)\n\nAnalysis of Variance Table\n\nResponse: severity\n                   Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreat               1 0.113232 0.113232  30.358 4.754e-05 ***\nfactor(dose)        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:factor(dose)  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals          16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nVerificação das premissas e discriminação dos grupos\n\nlibrary(DHARMa)\nplot(simulateResiduals(mf))\n\n\n\nmf_medias &lt;- emmeans(mf, ~ treat | dose)\nmf_medias\n\ndose = 0.5:\n treat        emmean     SE df lower.CL upper.CL\n Ionic liquid 0.2921 0.0273 16  0.23420   0.3500\n Tebuconazole 0.0210 0.0273 16 -0.03690   0.0789\n\ndose = 2.0:\n treat        emmean     SE df lower.CL upper.CL\n Ionic liquid 0.0501 0.0273 16 -0.00781   0.1080\n Tebuconazole 0.0202 0.0273 16 -0.03768   0.0781\n\nConfidence level used: 0.95 \n\nlibrary(multcomp)\nlibrary(MASS)\ncld(mf_medias)\n\ndose = 0.5:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0210 0.0273 16 -0.03690   0.0789  1    \n Ionic liquid 0.2921 0.0273 16  0.23420   0.3500   2   \n\ndose = 2.0:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0202 0.0273 16 -0.03768   0.0781  1    \n Ionic liquid 0.0501 0.0273 16 -0.00781   0.1080  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula9.html",
    "href": "Aula9.html",
    "title": "aula 9",
    "section": "",
    "text": "Um experimento pode ser realizado com diferentes arranjos, ou seja, a forma como dois ou mais fatores estudados ao mesmo tempo são esquematizados. Os arranjos mais utilizados são o fatorial e parcelas subdivididas, podendo ser também combinados.\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gsheet)\nmilho &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759\")\n\n\n\n\n\nmilho %&gt;% \n  ggplot(aes(hybrid, index)) +\n  geom_col()\n\n\n\nmilho %&gt;% \n  ggplot(aes(hybrid, yield)) +\n  geom_col()\n\n\n\nmilho %&gt;% \n  ggplot(aes(method, index)) +\n  geom_jitter(width = 0.01, alpha = 0.2)+\n  facet_wrap(~ hybrid) +\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5, color= \"blue\")\n\n\n\nmilho %&gt;% \n  ggplot(aes(method, yield)) +\n  geom_jitter(width = 0.01, alpha = 0.2)+\n  facet_wrap(~ hybrid) +\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5, color= \"blue\")"
  },
  {
    "objectID": "Aula9.html#modelo-misto",
    "href": "Aula9.html#modelo-misto",
    "title": "aula 9",
    "section": "",
    "text": "Um experimento pode ser realizado com diferentes arranjos, ou seja, a forma como dois ou mais fatores estudados ao mesmo tempo são esquematizados. Os arranjos mais utilizados são o fatorial e parcelas subdivididas, podendo ser também combinados.\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gsheet)\nmilho &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759\")\n\n\n\n\n\nmilho %&gt;% \n  ggplot(aes(hybrid, index)) +\n  geom_col()\n\n\n\nmilho %&gt;% \n  ggplot(aes(hybrid, yield)) +\n  geom_col()\n\n\n\nmilho %&gt;% \n  ggplot(aes(method, index)) +\n  geom_jitter(width = 0.01, alpha = 0.2)+\n  facet_wrap(~ hybrid) +\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5, color= \"blue\")\n\n\n\nmilho %&gt;% \n  ggplot(aes(method, yield)) +\n  geom_jitter(width = 0.01, alpha = 0.2)+\n  facet_wrap(~ hybrid) +\n  stat_summary(fun.data = \"mean_cl_boot\", size = 0.5, color= \"blue\")"
  },
  {
    "objectID": "Aula9.html#anova-parcela-subdividida---index",
    "href": "Aula9.html#anova-parcela-subdividida---index",
    "title": "aula 9",
    "section": "Anova parcela subdividida - Index",
    "text": "Anova parcela subdividida - Index\nPara realização dessa análise, devemos considerar o bloco como um fator. Além disso, devemos observar a interação dos fatores híbrido e método, bem como com o bloco.\n\nlibrary(tidyverse)\nlibrary(lme4)\n\nCarregando pacotes exigidos: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nlibrary(Matrix)\n\nmilho &lt;- milho %&gt;%  \n  mutate(block = as.factor(block))\n\nmix2 &lt;- lmer(index ~ hybrid*method + block +\n               (1|block/hybrid), data = milho)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nunable to evaluate scaled gradient\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge: degenerate Hessian with 1 negative eigenvalues\n\nlibrary(car)\n\nCarregando pacotes exigidos: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\nAnova(mix2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.5971  5   0.008094 **\nmethod         4.6963  1   0.030228 * \nblock          0.2157  3   0.975023   \nhybrid:method 15.8060  5   0.007420 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nInterpretação: Pelo menos um híbrido se diferencia dos demais. Assim como existe diferença significativa entre os métodos, existe diferença na interação híbrido com método\n\nChecando as premissas\n\nlibrary(DHARMa)\n\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nplot(simulateResiduals(mix2))\n\n\n\nlibrary(performance)\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.635).\n\ncheck_heteroscedasticity(mix2)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n\n\n\n\nTransformação para raiz quadrada e ANOVA\n\nmix22 &lt;- lmer(sqrt(index) ~ hybrid*method + block +\n               (1|block/hybrid), data = milho)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nunable to evaluate scaled gradient\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge: degenerate Hessian with 1 negative eigenvalues\n\nlibrary(car)\nAnova(mix22)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(index)\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.3159  5   0.009095 **\nmethod         3.8886  1   0.048615 * \nblock          0.0718  3   0.994997   \nhybrid:method 13.3812  5   0.020057 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nChecando as premissas após transformação\n\nlibrary(DHARMa)\nplot(simulateResiduals(mix22))\n\n\n\nlibrary(performance)\ncheck_normality(mix22)\n\nOK: residuals appear as normally distributed (p = 0.440).\n\ncheck_heteroscedasticity(mix22)\n\nOK: Error variance appears to be homoscedastic (p = 0.971).\n\n\n\n\nVerificação dos grupos distintos estatisticamente\n\nlibrary(emmeans)\n\nWelcome to emmeans.\nCaution: You lose important information if you filter this package's results.\nSee '? untidy'\n\nmedias_milho &lt;- emmeans(mix22, ~ hybrid | method,\n                        type = \"response\")\nmedias_milho2 &lt;- emmeans(mix22, ~ method | hybrid,\n                         type = \"response\")\n# quando transforma os dados e necessario adicionar type = response\n\nlibrary (multcomp)\n\nCarregando pacotes exigidos: mvtnorm\n\n\nCarregando pacotes exigidos: survival\n\n\nCarregando pacotes exigidos: TH.data\n\n\nCarregando pacotes exigidos: MASS\n\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\ncld (medias_milho,Letters = LETTERS)\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.4 10.7 6084     4.10     46.0  A    \n 30K64        20.3 10.9 6084     4.51     47.4  A    \n 30F53 YH     24.5 12.0 6084     6.61     53.7  AB   \n 30F53 HX     25.0 12.1 6084     6.84     54.4  AB   \n 30S31YH      31.7 13.7 6084    10.57     64.2  AB   \n 30S31H       37.1 14.8 6084    13.79     71.8   B   \n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.1 10.6 6084     3.96     45.6  A    \n 30K64        21.3 11.2 6084     5.00     48.9  A    \n 30F53 HX     24.4 12.0 6084     6.56     53.6  A    \n 30F53 YH     26.0 12.4 6084     7.42     56.0  A    \n 30S31H       26.3 12.5 6084     7.57     56.4  A    \n 30S31YH      26.4 12.5 6084     7.62     56.5  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\ncld (medias_milho2, Letters = LETTERS)\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 12.0 6084     6.56     53.6  A    \n pin        25.0 12.1 6084     6.84     54.4  A    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 12.0 6084     6.61     53.7  A    \n silk       26.0 12.4 6084     7.42     56.0  A    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.9 6084     4.51     47.4  A    \n silk       21.3 11.2 6084     5.00     48.9  A    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.5 6084     7.57     56.4  A    \n pin        37.1 14.8 6084    13.79     71.8   B   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.5 6084     7.62     56.5  A    \n pin        31.7 13.7 6084    10.57     64.2  A    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.6 6084     3.96     45.6  A    \n pin        19.4 10.7 6084     4.10     46.0  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula9.html#anova-parcela-subdividida---yield",
    "href": "Aula9.html#anova-parcela-subdividida---yield",
    "title": "aula 9",
    "section": "Anova parcela subdividida - Yield",
    "text": "Anova parcela subdividida - Yield\n\nmix3 &lt;- lmer(yield ~ hybrid*method + block +\n               (1|block/hybrid), data = milho)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nunable to evaluate scaled gradient\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nHessian is numerically singular: parameters are not uniquely determined\n\nlibrary(car)\nAnova(mix3)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yield\n                Chisq Df Pr(&gt;Chisq)    \nhybrid        25.5991  5  0.0001067 ***\nmethod         0.1052  1  0.7456934    \nblock          2.3564  3  0.5018078    \nhybrid:method 25.9302  5  9.206e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nChecando as premissas\n\nlibrary(DHARMa)\nplot(simulateResiduals(mix3))\n\n\n\nlibrary(performance)\ncheck_normality(mix3)\n\nOK: residuals appear as normally distributed (p = 0.211).\n\ncheck_heteroscedasticity(mix3)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n\n\n\nTransformação para raiz quadrada\n\nmix33 &lt;- lmer(sqrt(yield) ~ hybrid*method + block +\n               (1|block/hybrid), data = milho)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: large eigenvalue ratio\n - Rescale variables?\n\nlibrary(car)\nAnova(mix33)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(yield)\n                Chisq Df Pr(&gt;Chisq)    \nhybrid        25.5591  5  0.0001086 ***\nmethod         0.0520  1  0.8196750    \nblock          2.3606  3  0.5010021    \nhybrid:method 24.4985  5  0.0001741 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nChecando as premissas após transformação\n\nlibrary(DHARMa)\nplot(simulateResiduals(mix33))\n\n\n\nlibrary(performance)\ncheck_normality(mix33)\n\nOK: residuals appear as normally distributed (p = 0.214).\n\ncheck_heteroscedasticity(mix33)\n\nOK: Error variance appears to be homoscedastic (p = 0.686).\n\n\n\n\nVerificação dos grupos distintos estatisticamente\n\nlibrary(emmeans)\nmedias_milho3 &lt;- emmeans(mix33, ~ hybrid | method,\n                        type = \"response\")\nmedias_milho4 &lt;- emmeans(mix33, ~ method | hybrid,\n                         type = \"response\")\n\nlibrary (multcomp)\ncld (medias_milho3,Letters = LETTERS)\n\nmethod = pin:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      7829 732 26.1     6398     9405  A    \n 30S31H       8081 743 26.1     6626     9681  AB   \n 30F53 YH     9314 798 26.1     7746    11027  ABC  \n 30F53 HX    11130 872 26.1     9410    12995   BC  \n 30K64       11666 893 26.1     9903    13574    C  \n BG7049H     11914 903 26.1    10131    13841    C  \n\nmethod = silk:\n hybrid   response  SE   df lower.CL upper.CL .group\n 30S31YH      8257 751 26.1     6785     9873  A    \n 30F53 YH     9079 788 26.1     7532    10770  A    \n 30S31H       9135 790 26.1     7583    10832  A    \n 30F53 HX     9932 824 26.1     8311    11698  AB   \n 30K64       10331 840 26.1     8676    12131  AB   \n BG7049H     12822 936 26.1    10970    14818   B   \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\ncld (medias_milho4, Letters = LETTERS)\n\nhybrid = 30F53 HX:\n method response  SE   df lower.CL upper.CL .group\n silk       9932 824 26.1     8311    11698  A    \n pin       11130 872 26.1     9410    12995   B   \n\nhybrid = 30F53 YH:\n method response  SE   df lower.CL upper.CL .group\n silk       9079 788 26.1     7532    10770  A    \n pin        9314 798 26.1     7746    11027  A    \n\nhybrid = 30K64:\n method response  SE   df lower.CL upper.CL .group\n silk      10331 840 26.1     8676    12131  A    \n pin       11666 893 26.1     9903    13574   B   \n\nhybrid = 30S31H:\n method response  SE   df lower.CL upper.CL .group\n pin        8081 743 26.1     6626     9681  A    \n silk       9135 790 26.1     7583    10832   B   \n\nhybrid = 30S31YH:\n method response  SE   df lower.CL upper.CL .group\n pin        7829 732 26.1     6398     9405  A    \n silk       8257 751 26.1     6785     9873  A    \n\nhybrid = BG7049H:\n method response  SE   df lower.CL upper.CL .group\n pin       11914 903 26.1    10131    13841  A    \n silk      12822 936 26.1    10970    14818  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula9.html#análise-conjunta",
    "href": "Aula9.html#análise-conjunta",
    "title": "aula 9",
    "section": "Análise conjunta",
    "text": "Análise conjunta\nQuando há mais de um experimento também podemos realizar uma análise mista, em que é considerada uma média de todos os experimentos.\n\nlibrary(lme4)\nglm4 &lt;- glmer(nplants ~ trat + (trat|exp),\n            family = poisson,\n            data = estande)\n\nsummary(glm4)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.223397   0.147793  28.577  &lt; 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n\nAIC(glm4)\n\n[1] 660.7282\n\nglm4b &lt;- glmer(nplants ~ trat + (trat|exp),\n            family = poisson(link = \"log\"),\n            data = estande)\n\nsummary(glm4b)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.223397   0.147793  28.577  &lt; 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n\nAIC(glm4b)\n\n[1] 660.7282"
  },
  {
    "objectID": "Aula9.html#relação-entre-variáveis-respostas",
    "href": "Aula9.html#relação-entre-variáveis-respostas",
    "title": "aula 9",
    "section": "Relação entre variáveis respostas",
    "text": "Relação entre variáveis respostas\n\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBioconductor version '3.18' is out-of-date; the current release version '3.19'\n  is available with R version '4.4'; see https://bioconductor.org/install\n\nBiocManager::install(\"Icens\")\n\nBioconductor version 3.18 (BiocManager 1.30.23), R 4.3.3 (2024-02-29 ucrt)\n\n\nWarning: package(s) not installed when version(s) same as or greater than current; use\n  `force = TRUE` to re-install: 'Icens'\n\n\nInstallation paths not writeable, unable to update packages\n  path: C:/Program Files/R/R-4.3.3/library\n  packages:\n    boot, codetools, foreign, KernSmooth, lattice, nlme, survival\n\n\nOld packages: 'cli', 'crayon', 'digest', 'emmeans', 'lme4', 'minqa', 'mvtnorm',\n  'nloptr', 'parameters', 'pbkrtest', 'pkgload', 'ps', 'rlang', 'SparseM',\n  'xfun'\n\nremotes::install_github(\"emdelponte/r4pde\")\n\nDownloading GitHub repo emdelponte/r4pde@HEAD\n\n\nrlang (1.1.3 -&gt; 1.1.4) [CRAN]\ncli   (3.6.2 -&gt; 3.6.3) [CRAN]\n\n\nSkipping 1 packages not available: Icens\n\n\nInstalling 2 packages: rlang, cli\n\n\nInstalling packages into 'C:/Users/Windows/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\npackage 'rlang' successfully unpacked and MD5 sums checked\n\n\nWarning: cannot remove prior installation of package 'rlang'\n\n\nWarning in file.copy(savedcopy, lib, recursive = TRUE): problem copying\nC:\\Users\\Windows\\AppData\\Local\\R\\win-library\\4.3\\00LOCK\\rlang\\libs\\x64\\rlang.dll\nto C:\\Users\\Windows\\AppData\\Local\\R\\win-library\\4.3\\rlang\\libs\\x64\\rlang.dll:\nPermission denied\n\n\nWarning: restored 'rlang'\n\n\npackage 'cli' successfully unpacked and MD5 sums checked\n\n\nWarning: cannot remove prior installation of package 'cli'\n\n\nWarning in file.copy(savedcopy, lib, recursive = TRUE): problem copying\nC:\\Users\\Windows\\AppData\\Local\\R\\win-library\\4.3\\00LOCK\\cli\\libs\\x64\\cli.dll to\nC:\\Users\\Windows\\AppData\\Local\\R\\win-library\\4.3\\cli\\libs\\x64\\cli.dll:\nPermission denied\n\n\nWarning: restored 'cli'\n\n\n\nThe downloaded binary packages are in\n    C:\\Users\\Windows\\AppData\\Local\\Temp\\RtmpEvGUjf\\downloaded_packages\n── R CMD build ─────────────────────────────────────────────────────────────────\n* checking for file 'C:\\Users\\Windows\\AppData\\Local\\Temp\\RtmpEvGUjf\\remotes2af465736917\\emdelponte-r4pde-42e6615/DESCRIPTION' ... OK\n* preparing 'r4pde':\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\n* building 'r4pde_0.0.0.9000.tar.gz'\n\n\n\nInstalling package into 'C:/Users/Windows/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\nlibrary(r4pde)\n\nWarning: replacing previous import 'car::recode' by 'dplyr::recode' when\nloading 'r4pde'\n\nwm &lt;- WhiteMoldSoybean\n\nwm %&gt;% \n  ggplot(aes(inc,yld, color = factor(study))) + \n  geom_point() +\n  theme_minimal() +\n  geom_smooth(method = \"lm\", se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n# modelo global\nmofo1 &lt;- lm(yld ~inc,\n            data = wm)\n\nsummary(mofo1) \n\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3299.619     56.451  58.451  &lt; 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,   Adjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n\n#Intercept é a produtividade com a incidência igual a 0\n\n\nlibrary(broom)\nlibrary(dplyr)\n\nmofo2 &lt;- wm %&gt;% \n  group_by(study) %&gt;% \n  do(tidy(lm(.$yld ~ .$inc), conf.int = TRUE))\n\nmofo2\n\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n\np3 &lt;- mofo2 %&gt;% \n  filter(term == \"(Intercept)\") %&gt;% \n  ggplot(aes(x = estimate)) +\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\") +\n  theme_r4pde() +\n  labs(x = \"Intercept\", y = \"Frequency\")\n\nlibrary(cowplot)\n\n\nAttaching package: 'cowplot'\n\n\nThe following object is masked from 'package:lubridate':\n\n    stamp\n\np4 &lt;- mofo2 %&gt;% \n  filter(term == \".$inc\") %&gt;% \n  ggplot(aes(x = estimate)) +\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\") +\n  theme_r4pde() +\n  labs (x = \"Slope\", y = \"Frequency\")\n\ndf &lt;- mofo2 %&gt;%  filter(term == \".$inc\") \nmean(df$estimate)\n\n[1] -19.52932\n\nlibrary(patchwork)\n\n\nAttaching package: 'patchwork'\n\n\nThe following object is masked from 'package:cowplot':\n\n    align_plots\n\n\nThe following object is masked from 'package:MASS':\n\n    area\n\np3 + p4\n\n\n\n\n\nlibrary(lme4)\nmofo3 &lt;- lmer(yld ~ inc + (inc| study), data = wm,\n              REML = F)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n\nsummary(mofo3)\n\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: yld ~ inc + (inc | study)\n   Data: wm\n\n     AIC      BIC   logLik deviance df.resid \n  5319.4   5343.1  -2653.7   5307.4      376 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7078 -0.5991 -0.0295  0.5077  3.2364 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n study    (Intercept) 557573.08 746.708       \n          inc             36.85   6.071  -0.29\n Residual              37228.73 192.947       \nNumber of obs: 382, groups:  study, 35\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 3455.432    128.063   26.98\ninc          -17.236      1.451  -11.88\n\nCorrelation of Fixed Effects:\n    (Intr)\ninc -0.300\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n\nAnova (mofo3)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yld\n     Chisq Df Pr(&gt;Chisq)    \ninc 141.09  1  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nconfint(mofo3, method = \"Wald\")\n\n                 2.5 %     97.5 %\n.sig01              NA         NA\n.sig02              NA         NA\n.sig03              NA         NA\n.sigma              NA         NA\n(Intercept) 3204.43403 3706.43096\ninc          -20.08046  -14.39219\n\n\nInterpretação: Esta estimativa é mais confiável Inc do efeito ficou sendo -17, os outros métodos subestimam A medida que a incidência aumenta, a produtividade diminui em 17kg"
  }
]