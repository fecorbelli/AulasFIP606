---
title: "aula 9"
format: html
editor: visual
---

## Modelo misto

Um experimento pode ser realizado com diferentes arranjos, ou seja, a forma como dois ou mais fatores estudados ao mesmo tempo são esquematizados. Os arranjos mais utilizados são o fatorial e parcelas subdivididas, podendo ser também combinados.

### Importação dos dados

```{r}
library(tidyverse)
library(gsheet)
milho <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759")
```

### Visualização

```{r}

milho %>% 
  ggplot(aes(hybrid, index)) +
  geom_col()

milho %>% 
  ggplot(aes(hybrid, yield)) +
  geom_col()

milho %>% 
  ggplot(aes(method, index)) +
  geom_jitter(width = 0.01, alpha = 0.2)+
  facet_wrap(~ hybrid) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.5, color= "blue")

milho %>% 
  ggplot(aes(method, yield)) +
  geom_jitter(width = 0.01, alpha = 0.2)+
  facet_wrap(~ hybrid) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.5, color= "blue")
```

## Anova parcela subdividida - Index

Para realização dessa análise, devemos considerar o bloco como um fator. Além disso, devemos observar a interação dos fatores híbrido e método, bem como com o bloco.

```{r}
library(tidyverse)
library(lme4)
library(Matrix)

milho <- milho %>%  
  mutate(block = as.factor(block))

mix2 <- lmer(index ~ hybrid*method + block +
               (1|block/hybrid), data = milho)
library(car)
Anova(mix2)

```

Interpretação: Pelo menos um híbrido se diferencia dos demais. Assim como existe diferença significativa entre os métodos, existe diferença na interação híbrido com método

### Checando as premissas

```{r}
library(DHARMa)
plot(simulateResiduals(mix2))
library(performance)
check_normality(mix2)
check_heteroscedasticity(mix2)
```

### Transformação para raiz quadrada e ANOVA

```{r}
mix22 <- lmer(sqrt(index) ~ hybrid*method + block +
               (1|block/hybrid), data = milho)

library(car)
Anova(mix22)
```

### Checando as premissas após transformação

```{r}
library(DHARMa)
plot(simulateResiduals(mix22))
library(performance)
check_normality(mix22)
check_heteroscedasticity(mix22)

```

### Verificação dos grupos distintos estatisticamente

```{r}
library(emmeans)
medias_milho <- emmeans(mix22, ~ hybrid | method,
                        type = "response")
medias_milho2 <- emmeans(mix22, ~ method | hybrid,
                         type = "response")
# quando transforma os dados e necessario adicionar type = response

library (multcomp)
cld (medias_milho,Letters = LETTERS)
cld (medias_milho2, Letters = LETTERS)

```

## Anova parcela subdividida - Yield

```{r}
mix3 <- lmer(yield ~ hybrid*method + block +
               (1|block/hybrid), data = milho)
library(car)
Anova(mix3)
```

### Checando as premissas

```{r}
library(DHARMa)
plot(simulateResiduals(mix3))
library(performance)
check_normality(mix3)
check_heteroscedasticity(mix3)

```

### Transformação para raiz quadrada

```{r}
mix33 <- lmer(sqrt(yield) ~ hybrid*method + block +
               (1|block/hybrid), data = milho)

library(car)
Anova(mix33)
```

### Checando as premissas após transformação

```{r}
library(DHARMa)
plot(simulateResiduals(mix33))
library(performance)
check_normality(mix33)
check_heteroscedasticity(mix33)
```

### Verificação dos grupos distintos estatisticamente

```{r}
library(emmeans)
medias_milho3 <- emmeans(mix33, ~ hybrid | method,
                        type = "response")
medias_milho4 <- emmeans(mix33, ~ method | hybrid,
                         type = "response")

library (multcomp)
cld (medias_milho3,Letters = LETTERS)
cld (medias_milho4, Letters = LETTERS)

```

# Regressão linear

A análise de regressão permite estudar a relação entre uma variável dependente e uma ou mais variáveis independentes. Ela busca estimar uma equação que descreve a relação entre as variáveis.

### Importação dos dados

```{r}
library(gsheet)
estande <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555")

```

### Visualização

Para visualização da reta referente a regressão linear utilizamos o argumento method = “lm” dentro da função `geom_smooth()`.

```{r}
estande %>% 
  ggplot(aes(trat,nplants)) +
  geom_jitter(width = 0.01, alpha = 0.2) +
  facet_wrap(~ exp) +
   stat_summary(fun.data = "mean_cl_boot", size = 0.5, color= "blue") +
  geom_smooth(method = "lm", se = F)

#se = F -> tira a barra de intervalo de confiança

estande %>%  
  ggplot(aes(trat, nplants, color = factor(exp)))+
  geom_jitter(width = 0.1, color = "gray")+
  stat_summary(fun.data = "mean_cl_boot", color = "blue")+
  geom_smooth(method = "lm", se = F)
  
```

### Modelo de melhor ajuste - Experimento 1

Para analisar cada experimento isoladamente, primeiro filtramos o conjunto de dados com a função `filter()`. Depois ajustamos os dados ao modelo linear por meio da função `lm()`.

```{r}
exp1 <- estande %>% 
  filter(exp == 1)

exp1 %>% 
  ggplot (aes(trat, nplants)) +
  geom_point() +
  ylim(0,100) +
  geom_smooth(se = F) 

# modelo linear

lm1 <- lm(nplants ~ trat,
          data = exp1)

summary(lm1)
```

Interpretação: Se modelo linear é o que explica melhor, interceptaria em 52 Taxa de redução - 1 planta a cada 4% (-0.242) Ho - coeficiente angular igual a zero (modelo linear) pvalor = 0,21 - não rejeita Ho (taxa de redução não é diferente de zero)

### Modelo de melhor ajuste - Experimento 2

```{r}
exp2 <- estande %>% 
  filter(exp == 2)

exp2 %>% 
  ggplot (aes(trat, nplants)) +
  geom_point() +
  ylim(0,100) +
  geom_smooth(se = F) 

# modelo linear

lm2 <- lm(nplants ~ trat,
          data = exp2)

summary(lm2)
```

Interpretação: -0,70 plantas a cada unidade de x(inóculo) Pvalor significativo, rejeita Ho

### Modelo de melhor ajuste - Experimento 3

```{r}
exp3 <- estande %>% 
  filter(exp == 3)

exp3 %>% 
  ggplot (aes(trat, nplants)) +
  geom_point() +
  ylim(0,100) +
  geom_smooth(se = F) 

# modelo linear

lm3 <- lm(nplants ~ trat,
          data = exp3)

summary(lm3)
hist(residuals(lm3))
```

Interpretação: Coeficiente de determinação (adjusted R-squared): 59% da variabilidade do Y (número de plantas) é explicado pelo X (inóculo)

### Transformações para tornar os dados mais linearizados

Para tornar os dados mais linearizados e o ajuste ser melhor, podemos transformar o conjunto de dados. Para verificar qual transformação se enquadra melhor, observamos o valor de AIC. Quanto menor o AIC melhor o modelo/melhor ajuste.

```{r}
exp2 |> 
  ggplot(aes(log(trat), nplants))+
  geom_point()+
  ylim(0,100)+
  geom_smooth(se = F)


glm1 <- glm(nplants ~ trat,
            family = poisson,
            data = exp1)

summary(glm1)
AIC(glm1)


glm1b <- glm(nplants ~ trat,
            family = poisson(link = "log"),
            data = exp1)

summary(glm1b)
AIC(glm1b)

glm2 <- glm(nplants ~ trat,
            family = poisson,
            data = exp2)

summary(glm2)
AIC(glm2)

glm2b <- glm(nplants ~ trat,
            family = poisson(link = "log"),
            data = exp2)

summary(glm2b)
AIC(glm2b)

glm3 <- glm(nplants ~ trat,
            family = poisson,
            data = exp3)


summary(glm3)
AIC(glm3)

glm3b <- glm(nplants ~ trat,
            family = poisson(link = "log"),
            data = exp3)

summary(glm3b)
AIC(glm3b)
```

## Análise conjunta

Quando há mais de um experimento também podemos realizar uma análise mista, em que é considerada uma média de todos os experimentos.

```{r}

library(lme4)
glm4 <- glmer(nplants ~ trat + (trat|exp),
            family = poisson,
            data = estande)

summary(glm4)
AIC(glm4)

glm4b <- glmer(nplants ~ trat + (trat|exp),
            family = poisson(link = "log"),
            data = estande)

summary(glm4b)
AIC(glm4b)

```

## Relação entre variáveis respostas

```{r}
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("Icens")

remotes::install_github("emdelponte/r4pde")
library(r4pde)

wm <- WhiteMoldSoybean

wm %>% 
  ggplot(aes(inc,yld, color = factor(study))) + 
  geom_point() +
  theme_minimal() +
  geom_smooth(method = "lm", se = F)
  
  
# modelo global
mofo1 <- lm(yld ~inc,
            data = wm)

summary(mofo1) 
#Intercept é a produtividade com a incidência igual a 0
```

```{r}
library(broom)
library(dplyr)

mofo2 <- wm %>% 
  group_by(study) %>% 
  do(tidy(lm(.$yld ~ .$inc), conf.int = TRUE))

mofo2

p3 <- mofo2 %>% 
  filter(term == "(Intercept)") %>% 
  ggplot(aes(x = estimate)) +
  geom_histogram(bins = 8, color = "white", fill = "gray50") +
  theme_r4pde() +
  labs(x = "Intercept", y = "Frequency")

library(cowplot)
p4 <- mofo2 %>% 
  filter(term == ".$inc") %>% 
  ggplot(aes(x = estimate)) +
  geom_histogram(bins = 8, color = "white", fill = "gray50") +
  theme_r4pde() +
  labs (x = "Slope", y = "Frequency")

df <- mofo2 %>%  filter(term == ".$inc") 
mean(df$estimate)

library(patchwork)
p3 + p4
```

```{r}
library(lme4)
mofo3 <- lmer(yld ~ inc + (inc| study), data = wm,
              REML = F)

summary(mofo3)
Anova (mofo3)
confint(mofo3, method = "Wald")
```

Interpretação: Esta estimativa é mais confiável Inc do efeito ficou sendo -17, os outros métodos subestimam A medida que a incidência aumenta, a produtividade diminui em 17kg
